{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pickle as pkl\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Process, Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path('/mnt/209C31C29C3192F0/Datasets/Mimic-CXR/physionet.org/files/mimic-cxr/2.0.0/')\n",
    "\n",
    "# be careful here, loading both amounts to ~10GB of memory\n",
    "image_list = list(csv.DictReader(open(dataset_path / 'cxr-record-list.csv', 'r'), delimiter=','))         # list of dictionaries\n",
    "report_list = list(csv.DictReader(open(dataset_path / 'cxr-study-list.csv', 'r'), delimiter=','))           # list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of slices: 6\n",
      "[slice(0, 62851, None), slice(62851, 125702, None), slice(125702, 188553, None), slice(188553, 251404, None), slice(251404, 314255, None), slice(314255, 377110, None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62851/62851 [00:00<00:00, 1719441.68it/s]\n",
      "\n",
      "  0%|          | 0/62855 [00:00<?, ?it/s], 1871782.28it/s]\n",
      "100%|██████████| 62855/62855 [00:00<00:00, 2174041.58it/s]\n",
      "100%|██████████| 62851/62851 [00:00<00:00, 1594157.14it/s]\n",
      "100%|██████████| 62851/62851 [07:56<00:00, 131.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36681\n"
     ]
    }
   ],
   "source": [
    "dataset_length = len(image_list)\n",
    "\n",
    "n_proc = 6\n",
    "offset = 0\n",
    "\n",
    "chunksize = dataset_length // n_proc\n",
    "proc_slices = []\n",
    "\n",
    "for i_proc in range(n_proc):\n",
    "        chunkstart = int(offset + (i_proc * chunksize))\n",
    "        # make sure to include the division remainder for the last process\n",
    "        chunkend = int(offset + (i_proc + 1) * chunksize) if i_proc < n_proc - 1 else int(offset + dataset_length)\n",
    "        proc_slices.append(np.s_[chunkstart:chunkend])\n",
    "\n",
    "print(f'Number of slices: {len(proc_slices)}\\n{proc_slices}')\n",
    "\n",
    "def process(data, slice, rank):                    # split it up into slices\n",
    "    # preprocess reports and images\n",
    "    # iterate through images and find corresponding report\n",
    "    for image in tqdm(image_list[slice]):\n",
    "        image_path = image['path']\n",
    "\n",
    "        # only have p10 from data\n",
    "        if image_path.find('p10') == -1:\n",
    "                continue\n",
    "\n",
    "        # filter out LAT chest X-rays?\n",
    "\n",
    "        id = image['study_id']\n",
    "        # find corresponding report\n",
    "        report_path = None\n",
    "        for report in report_list:\n",
    "            if id in report['study_id']:\n",
    "                report_path = report['path']\n",
    "        \n",
    "        if report is None:\n",
    "                print(f'Not found report for image with path {image_path}, study id: {id} and dicom')\n",
    "                continue\n",
    "\n",
    "        entry = {'subject_id': report['subject_id'],\n",
    "                'study_id': id,\n",
    "                'dicom_id': image['dicom_id'],\n",
    "                'report_path': report_path,\n",
    "                'image_path': image_path,\n",
    "                }\n",
    "\n",
    "        data.append(entry)\n",
    "\n",
    "\n",
    "data = Manager().list()\n",
    "processes = []\n",
    "for i in range(n_proc):\n",
    "        p = Process(target=process, args=(data, proc_slices[i], i))  # Passing the list\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "for p in processes:\n",
    "        p.join()\n",
    "\n",
    "data_list = list(data)\n",
    "print(len(data_list))\n",
    "with open(dataset_path / 'images2reports.pkl', 'wb') as f:\n",
    "        pkl.dump(data_list, f, pkl.DEFAULT_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "30ec110bc924a9e139919a87e1ff85100b6c769b1dd45b8d281b6aff673f8e03"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('mlmi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
