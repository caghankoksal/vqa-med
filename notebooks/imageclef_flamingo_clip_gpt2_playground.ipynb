{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import pytorch_lightning as pl\n",
    "from PIL import Image\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM,PreTrainedTokenizerFast, GPT2Tokenizer\n",
    "from PIL import Image\n",
    "from tqdm import tqdm as tqdm\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from src.datasets.imageclef_dataset import ImageCLEF2021DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "augmentations = {\n",
    "    \n",
    "    'train': T.Compose([T.Resize((224,224)),\n",
    "                        T.ToTensor(),\n",
    "                        T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))]),\n",
    "    'val': T.Compose([T.Resize((224,224)),\n",
    "                        T.ToTensor(),\n",
    "                        T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))]),\n",
    "    'test': T.Compose([T.Resize((224,224)),\n",
    "                        T.ToTensor(),\n",
    "                        T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_params = {\n",
    "    \"root\": \"/Users/caghankoksal/Desktop/imageclef/\",\n",
    "    \"batch_size\": 32,\n",
    "    \"tokenizer\": \"gpt2\",\n",
    "    \"return_size\": False,\n",
    "    \"num_data_workers\": 0,\n",
    "    \"limit_num_samples\" : 128\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageclef_datamodule = ImageCLEF2021DataModule(**dataset_params,transforms=augmentations,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = imageclef_datamodule.train_dataloader()\n",
    "val_loader = imageclef_datamodule.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.multimodal.flamingo_module import FlamingoModule\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE_OF_TOKENIZER = 50257 #Â mimic_datamodule.train_dataset.tokenizer.vocab_size\n",
    "LANGUAGE_MODEL = 'gpt2'\n",
    "NUM_TOKENS = VOCAB_SIZE_OF_TOKENIZER +3 if LANGUAGE_MODEL==\"gpt2\" else 31092\n",
    "FLAMINGO_EMBED_DIM = 768\n",
    "DEPTH = 12\n",
    "NUM_HEADS = 8\n",
    "ATT_HEAD_DIM = 64\n",
    "CROOS_ATT_EVERY=3\n",
    "MEDIA_TOKEN_ID = imageclef_datamodule.train_dataset.tokenizer.all_special_ids[imageclef_datamodule.train_dataset.tokenizer.all_special_tokens.index('<image>')]\n",
    "PERCEIVER_NUM_LATENTS = 64\n",
    "PERCEIVER_DEPTH = 2\n",
    "IMAGE_ENCODER = \"clip\"\n",
    "PRETRAINED_CLIP_PATH = '/Users/caghankoksal/Desktop/development/PubMedCLIP_ViT32.pth'\n",
    "PRETRAINED_GPT2_PATH = \"/Users/caghankoksal/Desktop/development/TransformerPlay/gpt2-pytorch_model.bin\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained_clip_path: /Users/caghankoksal/Desktop/development/PubMedCLIP_ViT32.pth\n",
      "warmup_steps: 569\n",
      "num_tokens: 50260\n",
      "dim: 768\n",
      "depth: 12\n",
      "num_heads: 8\n",
      "dim_head: 64\n",
      "cross_attn_every: 3\n",
      "media_token_id: 50258\n",
      "perceiver_num_latents: 64\n",
      "perceiver_depth: 2\n",
      "image_encoder: clip\n",
      "language_model: gpt2\n",
      "pretrained_gpt2_path: /Users/caghankoksal/Desktop/development/TransformerPlay/gpt2-pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "model_hyperparams = {\n",
    "    'pretrained_clip_path': PRETRAINED_CLIP_PATH,\n",
    "    'warmup_steps': 569,\n",
    "    'num_tokens': NUM_TOKENS,\n",
    "    'dim': FLAMINGO_EMBED_DIM,\n",
    "    'depth': DEPTH,\n",
    "    'num_heads': NUM_HEADS,\n",
    "    'dim_head': ATT_HEAD_DIM,\n",
    "    'cross_attn_every': CROOS_ATT_EVERY,\n",
    "    'media_token_id': MEDIA_TOKEN_ID,\n",
    "    'perceiver_num_latents': PERCEIVER_NUM_LATENTS,\n",
    "    'perceiver_depth': PERCEIVER_DEPTH,\n",
    "    'image_encoder': IMAGE_ENCODER,\n",
    "    'language_model': LANGUAGE_MODEL,\n",
    "    'pretrained_gpt2_path': PRETRAINED_GPT2_PATH,\n",
    "}\n",
    "\n",
    "for k,v in model_hyperparams.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /var/folders/61/9c2llh9n2pjb81c4dmhmb67w0000gn/T/tmp02saf68j\n",
      "INFO:torch.distributed.nn.jit.instantiator:Writing /var/folders/61/9c2llh9n2pjb81c4dmhmb67w0000gn/T/tmp02saf68j/_remote_module_non_sriptable.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained clip is being loaded\n",
      "Flamingo is being initialized with  gpt2  as language model\n",
      "GPT 2 Weights are loading...\n",
      "Loaded GPT2 weights and Embeddings num_weights loaded :  156\n"
     ]
    }
   ],
   "source": [
    "model = FlamingoModule(**model_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "trainer = pl.Trainer(max_epochs=6,\n",
    "                     accelerator=\"cpu\", devices=1,\n",
    "                     callbacks=[lr_monitor],\n",
    "                     log_every_n_steps=1,\n",
    "                      )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | flamingo_palm | FlamingoModel | 249 M \n",
      "------------------------------------------------\n",
      "76.8 M    Trainable params\n",
      "172 M     Non-trainable params\n",
      "249 M     Total params\n",
      "998.888   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41398c1bcbe4429d9560de6276c2601f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c91a9c6a0974612bbb81ba100003823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch-nightly')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "892a7f8aeabe86b99d45932805d162784b758c544538f3ce4737e4a115db3cfd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
