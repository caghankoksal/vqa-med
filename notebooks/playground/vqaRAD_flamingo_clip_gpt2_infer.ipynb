{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrei/anaconda3/envs/mlmi/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "import torch\n",
    "sys.path.append('../..')\n",
    "\n",
    "import os\n",
    "import pytorch_lightning as pl\n",
    "from src.datasets.vqa_rad_dataset import VQRadDataModule\n",
    "from src.models.multimodal.flamingo_module import FlamingoModule\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from pytorch_lightning.loggers import CometLogger\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "seed_everything(42, workers=True)\n",
    "\n",
    "img_mean = (0.48,0.48,0.48)\n",
    "img_std = (0.265,0.265,0.265)\n",
    "\n",
    "transforms = {'train':\n",
    "    T.Compose(\n",
    "    [\n",
    "        # T.RandomRotation(10),\n",
    "        T.ToTensor(),\n",
    "        # T.Normalize(mean=img_mean, std=img_std)\n",
    "    ]),\n",
    "    'val':\n",
    "    T.Compose(\n",
    "    [\n",
    "        # T.RandomRotation(10),\n",
    "        T.ToTensor(),\n",
    "        # T.Normalize(mean=img_mean, std=img_std)\n",
    "    ]),\n",
    "    'test':\n",
    "    T.Compose(\n",
    "    [\n",
    "        T.ToTensor(),\n",
    "        # T.Normalize(mean=img_mean, std=img_std)\n",
    "    ])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 794 QA pairs in VQA-RAD dataset\n",
      "Dataset root: /home/andrei/mlmi/home/mlmi-matthias/Data/VQA_RAD_preprocessed/\n",
      "Loading all images into memory... for train\n",
      "Found 107 images\n",
      "Dataset root: /home/andrei/mlmi/home/mlmi-matthias/Data/VQA_RAD_preprocessed/\n",
      "Loading all images into memory... for val\n",
      "Found 107 images\n",
      "Dataset root: /home/andrei/mlmi/home/mlmi-matthias/Data/VQA_RAD_preprocessed/\n",
      "Loading all images into memory... for test\n",
      "Found 107 images\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "NUM_DATA_WORKERS  = 8\n",
    "ONLY_IMAGES = False\n",
    "BATCH_SIZE = 1\n",
    "NUM_EPOCHS = 10\n",
    "LIMIT_NUM_SAMPLES = None\n",
    "\n",
    "ACCELERATOR = \"gpu\"\n",
    "DEVICES = [4]\n",
    "# ACCELERATOR = \"cpu\"\n",
    "# DEVICES = 1\n",
    "DATASET_ROOT = '/home/andrei/mlmi/home/mlmi-matthias/Data/VQA_RAD_preprocessed/'\n",
    "PRETRAINED_CLIP_PATH = '/home/andrei/mlmi/home/mlmi-matthias/Caghan/pretrained_models/PubMedCLIP_ViT32.pth'\n",
    "PRETRAINED_GPT2_PATH = \"/home/andrei/mlmi/home/mlmi-matthias/Caghan/pretrained_models/gpt2-pytorch_model.bin\"\n",
    "ANSWERS_LIST_PATH = '/home/andrei/mlmi/home/mlmi-matthias/VQA-RAD/unique_answers.pkl'\n",
    "\n",
    "IMAGE_TYPE = \"jpg\"\n",
    "SHUFFLE = True\n",
    "TOKENIZER  = \"gpt2\"\n",
    "LOAD_IN_MEM = True\n",
    "PREPROCESSED = True\n",
    "\n",
    "vqarad_datamodule = VQRadDataModule(\n",
    "                                batch_size=BATCH_SIZE, transforms=transforms, root=DATASET_ROOT,\n",
    "                                limit_num_samples=LIMIT_NUM_SAMPLES, num_workers=NUM_DATA_WORKERS, shuffle=SHUFFLE,\n",
    "                                tokenizer=\"gpt2\", preprocessed=PREPROCESSED, load_in_memory=LOAD_IN_MEM, answers_list_path=ANSWERS_LIST_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = vqarad_datamodule.train_dataloader()\n",
    "val_loader = vqarad_datamodule.val_dataloader()\n",
    "test_loader = vqarad_datamodule.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL HPRAMS\n",
    "VOCAB_SIZE_OF_TOKENIZER = 50257 # mimic_datamodule.train_dataset.tokenizer.vocab_size\n",
    "LANGUAGE_MODEL = 'gpt2'\n",
    "NUM_TOKENS = VOCAB_SIZE_OF_TOKENIZER +3 if LANGUAGE_MODEL==\"gpt2\" else 31092\n",
    "FLAMINGO_EMBED_DIM = 768\n",
    "DEPTH = 12\n",
    "NUM_HEADS = 8\n",
    "ATT_HEAD_DIM = 64\n",
    "CROOS_ATT_EVERY=3\n",
    "MEDIA_TOKEN_ID = vqarad_datamodule.train_dataset.tokenizer.\\\n",
    "    all_special_ids[vqarad_datamodule.train_dataset.tokenizer.all_special_tokens.index('<image>')]\n",
    "PERCEIVER_NUM_LATENTS = 64\n",
    "PERCEIVER_DEPTH = 2\n",
    "IMAGE_ENCODER = \"clip\"\n",
    "\n",
    "\n",
    "\n",
    "print(\"LANGUAGE_MODEL : \",LANGUAGE_MODEL, \"\\n\"\n",
    "        \"NUM_TOKENS : \",NUM_TOKENS, \"\\n\"\n",
    "        \"FLAMINGO_EMBED_DIM : \",FLAMINGO_EMBED_DIM, \"\\n\"\n",
    "        \"DEPTH : \",DEPTH, \"\\n\"\n",
    "        \"NUM_HEADS : \",NUM_HEADS, \"\\n\"\n",
    "        \"ATT_HEAD_DIM : \",ATT_HEAD_DIM, \"\\n\"\n",
    "        \"CROOS_ATT_EVERY : \",CROOS_ATT_EVERY, \"\\n\"\n",
    "        \"MEDIA_TOKEN_ID : \",MEDIA_TOKEN_ID, \"\\n\"\n",
    "        \"PERCEIVER_NUM_LATENTS : \",PERCEIVER_NUM_LATENTS, \"\\n\"\n",
    "        \"PERCEIVER_DEPTH : \",PERCEIVER_DEPTH, \"\\n\"\n",
    "        \"IMAGE_ENCODER : \",IMAGE_ENCODER, \"\\n\"\n",
    "        \"PRETRAINED_CLIP_PATH : \",PRETRAINED_CLIP_PATH, \"\\n\"\n",
    "        \"PRETRAINED_GPT2_PATH : \",PRETRAINED_GPT2_PATH, \"\\n\")\n",
    "\n",
    "\n",
    "hyperparams = {\n",
    "    'pretrained_clip_path': PRETRAINED_CLIP_PATH,\n",
    "    'warmup_steps': 0,\n",
    "    'num_tokens': NUM_TOKENS,\n",
    "    'dim': FLAMINGO_EMBED_DIM,\n",
    "    'depth': DEPTH,\n",
    "    'num_heads': NUM_HEADS,\n",
    "    'dim_head': ATT_HEAD_DIM,\n",
    "    'cross_attn_every': CROOS_ATT_EVERY,\n",
    "    'media_token_id': MEDIA_TOKEN_ID,\n",
    "    'perceiver_num_latents': PERCEIVER_NUM_LATENTS,\n",
    "    'perceiver_depth': PERCEIVER_DEPTH,\n",
    "    'image_encoder': IMAGE_ENCODER,\n",
    "    'language_model': LANGUAGE_MODEL,\n",
    "    'pretrained_gpt2_path': PRETRAINED_GPT2_PATH,\n",
    "}\n",
    "\n",
    "\n",
    "model = FlamingoModule(**hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECKPOINT_PATH = \"/home/andrei/mlmi/home/mlmi-matthias/Andrei/mlmi-vqa/notebooks/lightning_logs/flamingo_clip_GPT2_FT_vqaRAD_MIMICback_lr1e-4_Xray/checkpoints/epoch=5-val_loss=1.35-other_metric=0.00.ckpt\"\n",
    "# CHECKPOINT_PATH = \"/home/andrei/mlmi/home/mlmi-matthias/Andrei/mlmi-vqa/notebooks/lightning_logs/flamingo_clip_GPT2_FT_vqaRAD_MIMICback_all/checkpoints/epoch=59-val_loss=1.48-other_metric=0.00.ckpt\"\n",
    "CHECKPOINT_PATH = \"/home/andrei/mlmi/home/mlmi-matthias/Andrei/mlmi-vqa/notebooks/lightning_logs/flamingo_clip_GPT2_FT_vqaRAD_ROCOback_all/checkpoints/epoch=78-val_loss=1.53-other_metric=0.00.ckpt\"\n",
    "\n",
    "START_FROM_CHECKPOINT = True\n",
    "\n",
    "if START_FROM_CHECKPOINT:\n",
    "    print(\"Pretrained Flamingo Model is loaded from checkpoint : \",CHECKPOINT_PATH)\n",
    "    model.load_state_dict(torch.load(CHECKPOINT_PATH)[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "from transformers import GPT2Tokenizer\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn as nn\n",
    "import torch.nn.functional as F\n",
    "def generate(image, context, cur_model, ntok=20):\n",
    "    for _ in range(ntok):\n",
    "        out = cur_model({'image': image,'input_ids': context })\n",
    "        logits = out[:, -1, :]\n",
    "        indices_to_remove = logits < torch.topk(logits, 10)[0][..., -1, None]\n",
    "        logits[indices_to_remove] = np.NINF\n",
    "        next_tok = torch.multinomial(F.softmax(logits, dim=-1), num_samples=1).squeeze(1)\n",
    "        context = torch.cat([context, next_tok.unsqueeze(-1)], dim=-1)\n",
    "    return context\n",
    "\n",
    "\n",
    "tokenizer = vqarad_datamodule.train_dataset.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader_iter = iter(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = next(val_loader_iter)\n",
    "val_img = batch[\"image\"]\n",
    "context   = torch.tensor([tokenizer.encode(\"<|endoftext|> <image> question: \"+batch[\"question\"][0] + ' answer:')]) \n",
    "out = generate(val_img, context, model, ntok=20)\n",
    "print(\"Model out : \",tokenizer.decode(out[0]))\n",
    "print(\"Correct Answer: \" + batch[\"answer\"][0])\n",
    "plt.imshow(torch.swapaxes(val_img.squeeze(0),0,2), cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_img = batch[\"image\"]\n",
    "context   = torch.tensor([tokenizer.encode(\"<|endoftext|> <image> question: \"+batch[\"question\"][0] + ' answer:')])\n",
    "out = generate(val_img, context, model, ntok=20)\n",
    "print(\"Model out : \",tokenizer.decode(out[0]))\n",
    "print(\"Correct Answer: \" + batch[\"answer\"][0])\n",
    "plt.imshow(torch.swapaxes(val_img.squeeze(0),0,2), cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader_iter = iter(val_loader)\n",
    "cos_similarity = torch.nn.CosineSimilarity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import no_grad\n",
    "\n",
    "\n",
    "def generate_logits(image, pred_context, GT_context, GT_answer, model, ntok):\n",
    "\n",
    "    # get a prediction (whole answer)\n",
    "    pred_out_logits = None\n",
    "    pred_answer = torch.tensor([[]])\n",
    "    for i in range(ntok):\n",
    "        out = model({'image': image,'input_ids': pred_context})\n",
    "        logits = out[:, -1, :]\n",
    "        indices_to_remove = logits < torch.topk(logits, 10)[0][..., -1, None]\n",
    "        logits[indices_to_remove] = np.NINF\n",
    "        next_tok = torch.multinomial(F.softmax(logits, dim=-1), num_samples=1).squeeze(1)\n",
    "        pred_answer = torch.cat([pred_answer, next_tok.unsqueeze(-1)], dim=-1)\n",
    "        pred_context = torch.cat([pred_context, next_tok.unsqueeze(-1)], dim=-1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        # only get embeddings for answer and GT from the model\n",
    "        answer = tokenizer.decode(pred_answer[pred_answer!=50257].int())                # remove padding tokens, <EOC> token remains\n",
    "        # print(f'Ans: {answer}')\n",
    "        pred_answer = torch.tensor([tokenizer.encode(\"<|endoftext|> \" + answer)])\n",
    "        pred_out_logits = model.forward({'image': image,'input_ids': pred_answer}, return_embeds=True)\n",
    "        real_out_logits  = model.forward({'image': image,'input_ids': GT_answer}, return_embeds=True)\n",
    "\n",
    "    return pred_context, pred_out_logits, real_out_logits, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(val_loader_iter)\n",
    "val_img = batch[\"image\"]\n",
    "pred_context  = torch.tensor([tokenizer.encode(\"<|endoftext|> <image> question: \"+ batch[\"question\"][0] + ' answer:')]) \n",
    "GT_context  = torch.tensor([tokenizer.encode(\"<|endoftext|> <image> question: \"+ batch[\"question\"][0] + ' answer: ' + batch[\"answer\"][0] + '<EOC>')])\n",
    "GT_answer =  torch.tensor([tokenizer.encode(\"<|endoftext|> \" + batch[\"answer\"][0] + ' <EOC>')])\n",
    "out, pred_out_logits, real_out_logits, answer = generate_logits(val_img, pred_context, GT_context, GT_answer, model, ntok=20, batch=batch)\n",
    "\n",
    "print(\"Model out : \",tokenizer.decode(out[out != 50257]))\n",
    "print(\"Correct Answer: \" + batch[\"answer\"][0])\n",
    "\n",
    "# print(f'Answer: {tokenizer.encode(answer[:-1])}')\n",
    "\n",
    "pred = torch.mean(pred_out_logits, dim=1)\n",
    "real = torch.mean(real_out_logits, dim=1)\n",
    "\n",
    "torch.nn.functional.cosine_similarity(pred, real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import umap.plot\n",
    "\n",
    "reducer = umap.UMAP()\n",
    "data = torch.cat([preds, reals], dim=0).detach().numpy()\n",
    "labels = torch.cat([torch.zeros(preds.shape[0]), torch.ones(reals.shape[0])])\n",
    "# data = torch.tensor(preds)\n",
    "print(f'data: {data.shape}')\n",
    "print(f'labels: {labels.shape}')\n",
    "mapper = reducer.fit(data)\n",
    "umap.plot.points(mapper, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do validation dataset eval\n",
    "val_loader_iter = iter(val_loader)\n",
    "n = len(val_loader)\n",
    "print(f'validation dataset has {n} samples')\n",
    "\n",
    "preds = torch.tensor([])\n",
    "reals = torch.tensor([])\n",
    "\n",
    "similarity_num = 0\n",
    "identical_num = 0\n",
    "\n",
    "for sample in val_loader_iter:\n",
    "    val_img = sample[\"image\"]\n",
    "    pred_context  = torch.tensor([tokenizer.encode(\"<|endoftext|> <image> question: \"+ sample[\"question\"][0] + ' answer:')]) \n",
    "    GT_context  = torch.tensor([tokenizer.encode(\"<|endoftext|> <image> question: \"+ sample[\"question\"][0] + ' answer: ' + sample[\"answer\"][0] + '<EOC>')])\n",
    "    GT_answer =  torch.tensor([tokenizer.encode(\"<|endoftext|> \" + sample[\"answer\"][0] + ' <EOC>')])\n",
    "    out, pred_out_logits, real_out_logits, answer = generate_logits(val_img, pred_context, GT_context, GT_answer, model, ntok=20)\n",
    "\n",
    "    pred = torch.mean(pred_out_logits, dim=1)\n",
    "    real = torch.mean(real_out_logits, dim=1)\n",
    "\n",
    "    ans = answer.replace('<EOC>','')\n",
    "    # print(f'gt {sample[\"answer\"][0].strip()}\\npred: {ans.strip()}')\n",
    "\n",
    "    if sample[\"answer\"][0].strip().lower() == ans.strip().lower():\n",
    "        identical_num += 1\n",
    "\n",
    "    similarity = cos_similarity(pred, real)\n",
    "    if similarity.detach().numpy()[0] > 0.95:\n",
    "        print(\"Model out : \",tokenizer.decode(out[out != 50257]))\n",
    "        print(\"Correct Answer: \" + sample[\"answer\"][0])\n",
    "        similarity_num += 1\n",
    "        if similarity_num % 10 == 0:\n",
    "            print(f'Another 10..')\n",
    "        preds = torch.cat([preds,pred], dim=1)\n",
    "        reals = torch.cat([reals,real], dim=1)\n",
    "\n",
    "print(f'There were {similarity_num} TPs out of {n}')\n",
    "print(f'There were {identical_num} identi cal answers out of {n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do validation dataset eval\n",
    "test_loader_iter = iter(test_loader)\n",
    "n = len(test_loader)\n",
    "print(f'validation dataset has {n} samples')\n",
    "\n",
    "preds = torch.tensor([])\n",
    "reals = torch.tensor([])\n",
    "\n",
    "similarity_num = 0\n",
    "identical_num = 0\n",
    "\n",
    "for sample in test_loader_iter:\n",
    "    val_img = sample[\"image\"]\n",
    "    pred_context  = torch.tensor([tokenizer.encode(\"<|endoftext|> <image> question: \"+ sample[\"question\"][0] + ' answer:')]) \n",
    "    GT_context  = torch.tensor([tokenizer.encode(\"<|endoftext|> <image> question: \"+ sample[\"question\"][0] + ' answer: ' + sample[\"answer\"][0] + '<EOC>')])\n",
    "    GT_answer =  torch.tensor([tokenizer.encode(\"<|endoftext|> \" + sample[\"answer\"][0] + ' <EOC>')])\n",
    "    out, pred_out_logits, real_out_logits, answer = generate_logits(val_img, pred_context, GT_context, GT_answer, model, ntok=20)\n",
    "\n",
    "    pred = torch.mean(pred_out_logits, dim=1)\n",
    "    real = torch.mean(real_out_logits, dim=1)\n",
    "\n",
    "    ans = answer.replace('<EOC>','')\n",
    "    # print(f'gt {sample[\"answer\"][0].strip()}\\npred: {ans.strip()}')\n",
    "\n",
    "    if sample[\"answer\"][0].strip().lower() == ans.strip().lower():\n",
    "        identical_num += 1\n",
    "\n",
    "    similarity = cos_similarity(pred, real)\n",
    "    if similarity.detach().numpy()[0] > 0.95:\n",
    "        # print(\"Model out : \",tokenizer.decode(out[out != 50257]))\n",
    "        # print(\"Correct Answer: \" + sample[\"answer\"][0])\n",
    "        similarity_num += 1\n",
    "        if similarity_num % 10 == 0:\n",
    "            print(f'Another 10..')\n",
    "        preds = torch.cat([preds,pred], dim=1)\n",
    "        reals = torch.cat([reals,real], dim=1)\n",
    "\n",
    "print(f'There were {similarity_num} TPs out of {n}')\n",
    "print(f'There were {identical_num} identi cal answers out of {n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do it for the flamingo off ROCO model with classification head and EOQ token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = '/home/andrei/mlmi/home/mlmi-matthias/VQA-RAD'\n",
    "PRETRAINED_CLIP_PATH = '/home/andrei/mlmi/home/mlmi-matthias/Caghan/pretrained_models/PubMedCLIP_ViT32.pth'\n",
    "PRETRAINED_GPT2_PATH = \"/home/andrei/mlmi/home/mlmi-matthias/Caghan/pretrained_models/gpt2-pytorch_model.bin\"\n",
    "ANSWERS_LIST_PATH = '/home/andrei/mlmi/home/mlmi-matthias/VQA-RAD/unique_answers.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/andrei/mlmi/home/mlmi-matthias/Data/VQA_RAD_preprocessed/VQA-RAD_public.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/andrei/mlmi/home/mlmi-matthias/Andrei/mlmi-vqa/notebooks/playground/vqaRAD_flamingo_clip_gpt2_infer.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/andrei/mlmi/home/mlmi-matthias/Andrei/mlmi-vqa/notebooks/playground/vqaRAD_flamingo_clip_gpt2_infer.ipynb#ch0000019?line=11'>12</a>\u001b[0m PREPROCESSED \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/andrei/mlmi/home/mlmi-matthias/Andrei/mlmi-vqa/notebooks/playground/vqaRAD_flamingo_clip_gpt2_infer.ipynb#ch0000019?line=12'>13</a>\u001b[0m RETURN_IDX_EOC \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/andrei/mlmi/home/mlmi-matthias/Andrei/mlmi-vqa/notebooks/playground/vqaRAD_flamingo_clip_gpt2_infer.ipynb#ch0000019?line=14'>15</a>\u001b[0m RAD_datamodule \u001b[39m=\u001b[39m VQRadDataModule(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/andrei/mlmi/home/mlmi-matthias/Andrei/mlmi-vqa/notebooks/playground/vqaRAD_flamingo_clip_gpt2_infer.ipynb#ch0000019?line=15'>16</a>\u001b[0m                                 batch_size\u001b[39m=\u001b[39;49mBATCH_SIZE, transforms\u001b[39m=\u001b[39;49mtransforms, root\u001b[39m=\u001b[39;49mDATASET_ROOT,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/andrei/mlmi/home/mlmi-matthias/Andrei/mlmi-vqa/notebooks/playground/vqaRAD_flamingo_clip_gpt2_infer.ipynb#ch0000019?line=16'>17</a>\u001b[0m                                 limit_num_samples\u001b[39m=\u001b[39;49mLIMIT_NUM_SAMPLES, num_workers\u001b[39m=\u001b[39;49mNUM_DATA_WORKERS, shuffle\u001b[39m=\u001b[39;49mSHUFFLE,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/andrei/mlmi/home/mlmi-matthias/Andrei/mlmi-vqa/notebooks/playground/vqaRAD_flamingo_clip_gpt2_infer.ipynb#ch0000019?line=17'>18</a>\u001b[0m                                 tokenizer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt2\u001b[39;49m\u001b[39m\"\u001b[39;49m, preprocessed\u001b[39m=\u001b[39;49mPREPROCESSED, load_in_memory\u001b[39m=\u001b[39;49mLOAD_IN_MEM, answers_list_path\u001b[39m=\u001b[39;49mANSWERS_LIST_PATH,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/andrei/mlmi/home/mlmi-matthias/Andrei/mlmi-vqa/notebooks/playground/vqaRAD_flamingo_clip_gpt2_infer.ipynb#ch0000019?line=18'>19</a>\u001b[0m                                 return_idx_answer_eoc\u001b[39m=\u001b[39;49mRETURN_IDX_EOC\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/andrei/mlmi/home/mlmi-matthias/Andrei/mlmi-vqa/notebooks/playground/vqaRAD_flamingo_clip_gpt2_infer.ipynb#ch0000019?line=19'>20</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/andrei/mlmi/home/mlmi-matthias/Andrei/mlmi-vqa/notebooks/playground/vqaRAD_flamingo_clip_gpt2_infer.ipynb#ch0000019?line=21'>22</a>\u001b[0m train_loader \u001b[39m=\u001b[39m RAD_datamodule\u001b[39m.\u001b[39mtrain_dataloader()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/andrei/mlmi/home/mlmi-matthias/Andrei/mlmi-vqa/notebooks/playground/vqaRAD_flamingo_clip_gpt2_infer.ipynb#ch0000019?line=22'>23</a>\u001b[0m val_loader \u001b[39m=\u001b[39m RAD_datamodule\u001b[39m.\u001b[39mval_dataloader()\n",
      "File \u001b[0;32m~/mlmi/home/mlmi-matthias/Andrei/mlmi-vqa/notebooks/playground/../../src/datasets/vqa_rad_dataset.py:188\u001b[0m, in \u001b[0;36mVQRadDataModule.__init__\u001b[0;34m(self, batch_size, transforms, root, limit_num_samples, num_workers, shuffle, tokenizer, preprocessed, load_in_memory, answers_list_path, return_idx_answer_eoc)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msample_dicts \u001b[39m=\u001b[39m pkl\u001b[39m.\u001b[39mload(f)\n\u001b[1;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 188\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(root,\u001b[39m'\u001b[39;49m\u001b[39mVQA-RAD_public.json\u001b[39;49m\u001b[39m'\u001b[39;49m), \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    189\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msample_dicts \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n\u001b[1;32m    192\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mThere are \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msample_dicts)\u001b[39m}\u001b[39;00m\u001b[39m QA pairs in VQA-RAD dataset\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/andrei/mlmi/home/mlmi-matthias/Data/VQA_RAD_preprocessed/VQA-RAD_public.json'"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "NUM_DATA_WORKERS  = 8\n",
    "ONLY_IMAGES = False\n",
    "BATCH_SIZE = 1\n",
    "NUM_EPOCHS = 80\n",
    "LIMIT_NUM_SAMPLES = None\n",
    "\n",
    "IMAGE_TYPE = \"jpg\"\n",
    "SHUFFLE = True\n",
    "TOKENIZER  = \"gpt2\"\n",
    "LOAD_IN_MEM = True\n",
    "PREPROCESSED = False\n",
    "RETURN_IDX_EOC = True\n",
    "\n",
    "RAD_datamodule = VQRadDataModule(\n",
    "                                batch_size=BATCH_SIZE, transforms=transforms, root=DATASET_ROOT,\n",
    "                                limit_num_samples=LIMIT_NUM_SAMPLES, num_workers=NUM_DATA_WORKERS, shuffle=SHUFFLE,\n",
    "                                tokenizer=\"gpt2\", preprocessed=PREPROCESSED, load_in_memory=LOAD_IN_MEM, answers_list_path=ANSWERS_LIST_PATH,\n",
    "                                return_idx_answer_eoc=RETURN_IDX_EOC\n",
    ")\n",
    "\n",
    "train_loader = RAD_datamodule.train_dataloader()\n",
    "val_loader = RAD_datamodule.val_dataloader()\n",
    "test_loader = RAD_datamodule.test_dataloader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /tmp/tmprp0s0s7i\n",
      "INFO:torch.distributed.nn.jit.instantiator:Writing /tmp/tmprp0s0s7i/_remote_module_non_scriptable.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LANGUAGE_MODEL :  gpt2 \n",
      "NUM_TOKENS :  50261 \n",
      "FLAMINGO_EMBED_DIM :  768 \n",
      "DEPTH :  12 \n",
      "NUM_HEADS :  8 \n",
      "ATT_HEAD_DIM :  64 \n",
      "CROOS_ATT_EVERY :  3 \n",
      "MEDIA_TOKEN_ID :  50258 \n",
      "PERCEIVER_NUM_LATENTS :  64 \n",
      "PERCEIVER_DEPTH :  2 \n",
      "IMAGE_ENCODER :  clip \n",
      "PRETRAINED_CLIP_PATH :  /home/andrei/mlmi/home/mlmi-matthias/Caghan/pretrained_models/PubMedCLIP_ViT32.pth \n",
      "PRETRAINED_GPT2_PATH :  /home/andrei/mlmi/home/mlmi-matthias/Caghan/pretrained_models/gpt2-pytorch_model.bin \n",
      "\n",
      "Clip architecture is being loaded\n",
      "Clip pretrained weights are being loaded\n",
      "Flamingo is being initialized with  gpt2  as language model\n",
      "GPT 2 Weights are loading...\n",
      "Loaded GPT2 weights and Embeddings num_weights loaded :  156\n"
     ]
    }
   ],
   "source": [
    "# MODEL HPRAMS\n",
    "VOCAB_SIZE_OF_TOKENIZER = 50257 # mimic_datamodule.train_dataset.tokenizer.vocab_size\n",
    "LANGUAGE_MODEL = 'gpt2'\n",
    "NUM_TOKENS = VOCAB_SIZE_OF_TOKENIZER +4 if LANGUAGE_MODEL==\"gpt2\" else 31092\n",
    "FLAMINGO_EMBED_DIM = 768\n",
    "DEPTH = 12\n",
    "NUM_HEADS = 8\n",
    "ATT_HEAD_DIM = 64\n",
    "CROOS_ATT_EVERY=3\n",
    "MEDIA_TOKEN_ID = RAD_datamodule.train_dataset.tokenizer.\\\n",
    "    all_special_ids[RAD_datamodule.train_dataset.tokenizer.all_special_tokens.index('<image>')]\n",
    "PERCEIVER_NUM_LATENTS = 64\n",
    "PERCEIVER_DEPTH = 2\n",
    "IMAGE_ENCODER = \"clip\"\n",
    "CLASSIFICATION_MODE = True\n",
    "NUM_CLASSES = 25\n",
    "FLAMINGO_MODE = False\n",
    "LABEL_SMOOTHING = 0.2\n",
    "TOKEN_LABEL_SMOOTHING = 0.0\n",
    "GRADIENT_CLIP_VAL = 1\n",
    "LEARNING_RATE = 1e-4\n",
    "USE_IMAGE_EMBEDDINGS = True\n",
    "TRAIN_EMBEDDING_LAYER = True\n",
    "CLASSIFIER_DROPOUT = 0.5\n",
    "\n",
    "\n",
    "print(\"LANGUAGE_MODEL : \",LANGUAGE_MODEL, \"\\n\"\n",
    "        \"NUM_TOKENS : \",NUM_TOKENS, \"\\n\"\n",
    "        \"FLAMINGO_EMBED_DIM : \",FLAMINGO_EMBED_DIM, \"\\n\"\n",
    "        \"DEPTH : \",DEPTH, \"\\n\"\n",
    "        \"NUM_HEADS : \",NUM_HEADS, \"\\n\"\n",
    "        \"ATT_HEAD_DIM : \",ATT_HEAD_DIM, \"\\n\"\n",
    "        \"CROOS_ATT_EVERY : \",CROOS_ATT_EVERY, \"\\n\"\n",
    "        \"MEDIA_TOKEN_ID : \",MEDIA_TOKEN_ID, \"\\n\"\n",
    "        \"PERCEIVER_NUM_LATENTS : \",PERCEIVER_NUM_LATENTS, \"\\n\"\n",
    "        \"PERCEIVER_DEPTH : \",PERCEIVER_DEPTH, \"\\n\"\n",
    "        \"IMAGE_ENCODER : \",IMAGE_ENCODER, \"\\n\"\n",
    "        \"PRETRAINED_CLIP_PATH : \",PRETRAINED_CLIP_PATH, \"\\n\"\n",
    "        \"PRETRAINED_GPT2_PATH : \",PRETRAINED_GPT2_PATH, \"\\n\")\n",
    "\n",
    "\n",
    "hyperparams = {\n",
    "    'pretrained_clip_path': PRETRAINED_CLIP_PATH,\n",
    "    'warmup_steps': 30,\n",
    "    'num_tokens': NUM_TOKENS,\n",
    "    'dim': FLAMINGO_EMBED_DIM,\n",
    "    'depth': DEPTH,\n",
    "    'num_heads': NUM_HEADS,\n",
    "    'dim_head': ATT_HEAD_DIM,\n",
    "    'cross_attn_every': CROOS_ATT_EVERY,\n",
    "    'media_token_id': MEDIA_TOKEN_ID,\n",
    "    'perceiver_num_latents': PERCEIVER_NUM_LATENTS,\n",
    "    'perceiver_depth': PERCEIVER_DEPTH,\n",
    "    'image_encoder': IMAGE_ENCODER,\n",
    "    'language_model': LANGUAGE_MODEL,\n",
    "    'pretrained_gpt2_path': PRETRAINED_GPT2_PATH,\n",
    "    'classification_mode': CLASSIFICATION_MODE,\n",
    "    'classification_num_classes': NUM_CLASSES,  # 332 if DATASET==\"IMAGECLEF\"\n",
    "    'flamingo_mode': FLAMINGO_MODE,\n",
    "    \"label_smoothing\": LABEL_SMOOTHING,\n",
    "    \"token_label_smoothing\": TOKEN_LABEL_SMOOTHING,\n",
    "    \"learning_rate\":LEARNING_RATE,\n",
    "    \"use_image_embeddings\": USE_IMAGE_EMBEDDINGS,\n",
    "    \"train_embedding_layer\": TRAIN_EMBEDDING_LAYER,\n",
    "    \"classifier_dropout\": CLASSIFIER_DROPOUT\n",
    "}\n",
    "\n",
    "\n",
    "model = FlamingoModule(**hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained Flamingo Model is loaded from checkpoint :  /home/andrei/mlmi/home/mlmi-matthias/Andrei/mlmi-vqa/notebooks/lightning_logs/flamingo_clip_GPT2_FT_vqaRad_ROCOback_all_flamingoON_classification/checkpoints/epoch=36-val_acc_epoch=0.75-val_total_loss_epoch=3.03-val_loss_generation_epoch=1.27-val_classification_loss_epoch=1.76.ckpt\n"
     ]
    }
   ],
   "source": [
    "CHECKPOINT_PATH = \"/home/andrei/mlmi/home/mlmi-matthias/Andrei/mlmi-vqa/notebooks/lightning_logs/\\\n",
    "flamingo_clip_GPT2_FT_vqaRad_ROCOback_all_flamingoON_classification/checkpoints/\\\n",
    "epoch=36-val_acc_epoch=0.75-val_total_loss_epoch=3.03-val_loss_generation_epoch=1.27-val_classification_loss_epoch=1.76.ckpt\"\n",
    "START_FROM_CHECKPOINT = True\n",
    "\n",
    "if START_FROM_CHECKPOINT:\n",
    "    print(\"Pretrained Flamingo Model is loaded from checkpoint : \",CHECKPOINT_PATH)\n",
    "    model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=torch.device('cuda:1'))[\"state_dict\"],strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "from transformers import GPT2Tokenizer\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn as nn\n",
    "import torch.nn.functional as F\n",
    "def generate(image, context, cur_model, batch, ntok=20):\n",
    "    classification_logits = None\n",
    "    for _ in range(ntok):\n",
    "        out, classification_logits = cur_model({'image': image,'input_ids': context, \"index_eoq\": batch[\"index_eoq\"],\n",
    "        \"targets\": batch[\"targets\"],\"label\": batch[\"label\"]})\n",
    "        logits = out[:, -1, :]\n",
    "        indices_to_remove = logits < torch.topk(logits, 10)[0][..., -1, None]\n",
    "        logits[indices_to_remove] = np.NINF\n",
    "        #next_tok1 = torch.multinomial(F.softmax(logits, dim=-1), num_samples=1).squeeze(1)\n",
    "        #print(next_tok1.shape)\n",
    "        softmax_out = F.softmax(logits, dim=-1)\n",
    "        #print(softmax_out.shape)\n",
    "        next_tok = torch.argmax(softmax_out,dim=-1,keepdim=False)\n",
    "        #print(next_tok.shape)\n",
    "        context = torch.cat([context, next_tok.unsqueeze(-1)], dim=-1)\n",
    "    return context, classification_logits\n",
    "\n",
    "\n",
    "tokenizer = RAD_datamodule.train_dataset.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/405 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 405/405 [16:49<00:00,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 405/405 [16:49<00:00,  2.49s/it]\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "val_dataloader = RAD_datamodule.val_dataloader()\n",
    "tokenizer = RAD_datamodule.train_dataset.tokenizer\n",
    "true_predictions = []\n",
    "false_predictions = []\n",
    "classification = []\n",
    "for batch in tqdm(val_dataloader):\n",
    "    context   = torch.tensor([tokenizer.encode(\"<|endoftext|> <image> question: \"+batch[\"question\"][0] + ' <EOQ>'+ ' answer:')]) \n",
    "    out, classification_logits = generate(batch[\"image\"], context, model, batch, ntok=20)\n",
    "    # print(f'class shape: {classification_logits.shape}')\n",
    "    models_answer = tokenizer.decode(out[0]).split('answer:')[1].split('<EOC>')[0].rstrip().strip()\n",
    "    correct_answer = batch[\"answer\"][0].rstrip().strip()\n",
    "    if models_answer == correct_answer:\n",
    "        correct += 1\n",
    "        true_predictions.append((models_answer, correct_answer))\n",
    "    else:\n",
    "        false_predictions.append((models_answer, correct_answer))\n",
    "    classification.append((batch['label'], torch.argmax(classification_logits)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30864197530864196"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct/len(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "for tup in classification:\n",
    "    if tup[0] == tup[1]:\n",
    "        num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8740740740740741"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num/len(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/225 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [10:01<00:00,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [10:01<00:00,  2.67s/it]\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "test_dataloader = RAD_datamodule.test_dataloader()\n",
    "tokenizer = RAD_datamodule.train_dataset.tokenizer\n",
    "true_predictions = []\n",
    "false_predictions = []\n",
    "classification = []\n",
    "for batch in tqdm(test_dataloader):\n",
    "    context   = torch.tensor([tokenizer.encode(\"<|endoftext|> <image> question: \"+batch[\"question\"][0] + ' <EOQ>'+ ' answer:')]) \n",
    "    out, classification_logits = generate(batch[\"image\"], context, model, batch, ntok=20)\n",
    "    # print(f'class shape: {classification_logits.shape}')\n",
    "    models_answer = tokenizer.decode(out[0]).split('answer:')[1].split('<EOC>')[0].rstrip().strip()\n",
    "    correct_answer = batch[\"answer\"][0].rstrip().strip()\n",
    "    if models_answer == correct_answer:\n",
    "        correct += 1\n",
    "        true_predictions.append((models_answer, correct_answer))\n",
    "    else:\n",
    "        false_predictions.append((models_answer, correct_answer))\n",
    "    classification.append((batch['label'], torch.argmax(classification_logits)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = 0\n",
    "for tup in classification:\n",
    "    if tup[0] == tup[1]:\n",
    "        num += 1\n",
    "\n",
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num/len(test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 405/405 [00:58<00:00,  7.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 405/405 [00:58<00:00,  6.89it/s]\n",
      "100%|██████████| 225/225 [00:31<00:00,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [00:32<00:00,  7.00it/s]\n",
      "100%|██████████| 144/144 [00:00<00:00, 131959.75it/s]\n",
      "100%|██████████| 115/115 [00:00<00:00, 74758.98it/s]\n"
     ]
    }
   ],
   "source": [
    "# generate answer embeds\n",
    "val_loader_iter = iter(val_loader)\n",
    "test_loader_iter = iter(test_loader)\n",
    "\n",
    "val_answer_embeds = dict()\n",
    "\n",
    "# for val\n",
    "for batch in tqdm(val_loader_iter):\n",
    "    with torch.no_grad():\n",
    "        model.eval()     \n",
    "        ans = batch['answer'][0]\n",
    "        if ans not in val_answer_embeds.keys():\n",
    "            val_answer_embeds[ans] = torch.Tensor([])\n",
    "        GT_answer =  torch.tensor([tokenizer.encode(\"<|endoftext|> <image> question: \"+batch[\"question\"][0] + ' <EOQ>'+ ' answer: '+ batch[\"answer\"][0] + ' <EOC>')])\n",
    "        pred_out_logits, _ = model.forward({'image': batch['image'], 'input_ids': GT_answer}, return_embeds=True)\n",
    "        val_answer_embeds[ans] = torch.cat([val_answer_embeds[ans], torch.mean(pred_out_logits, dim=1)])\n",
    "\n",
    "test_answer_embeds = dict()\n",
    "\n",
    "# for test\n",
    "for batch in tqdm(test_loader_iter):\n",
    "    with torch.no_grad():\n",
    "        model.eval()     \n",
    "        ans = batch['answer'][0]\n",
    "        if ans not in test_answer_embeds.keys():\n",
    "            test_answer_embeds[ans] = torch.Tensor([])\n",
    "        GT_answer =  torch.tensor([tokenizer.encode(\"<|endoftext|> <image> question: \"+batch[\"question\"][0] + ' <EOQ>'+ ' answer: '+ batch[\"answer\"][0] + ' <EOC>')])\n",
    "        pred_out_logits, _ = model.forward({'image': batch['image'], 'input_ids': GT_answer}, return_embeds=True)\n",
    "        test_answer_embeds[ans] = torch.cat([test_answer_embeds[ans], torch.mean(pred_out_logits, dim=1)])\n",
    "\n",
    "# mean all possible answers for val\n",
    "for key in tqdm(val_answer_embeds.keys()):\n",
    "    if val_answer_embeds[key].shape[0] == 1:\n",
    "        continue\n",
    "    val_answer_embeds[key] = torch.mean(val_answer_embeds[key], dim=0).unsqueeze(0)\n",
    "\n",
    "# mean all possible answers for test\n",
    "for key in tqdm(test_answer_embeds.keys()):\n",
    "    if test_answer_embeds[key].shape[0] == 1:\n",
    "        continue\n",
    "    test_answer_embeds[key] = torch.mean(test_answer_embeds[key], dim=0).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_llogits(image, pred_context, model, ntok, batch):\n",
    "\n",
    "    # get a prediction (whole answer)\n",
    "    pred_out_logits = None\n",
    "    pred_answer = torch.tensor([[]])\n",
    "    for i in range(ntok):\n",
    "        out, classification = model.forward({'image': image,'input_ids': pred_context, 'index_eoq': batch['index_eoq'],\n",
    "        'targets': batch['targets'],'label': batch['label']})\n",
    "        logits = out[:, -1, :]\n",
    "        indices_to_remove = logits < torch.topk(logits, 10)[0][..., -1, None]\n",
    "        logits[indices_to_remove] = np.NINF\n",
    "        next_tok = torch.multinomial(F.softmax(logits, dim=-1), num_samples=1).squeeze(1)\n",
    "        pred_answer = torch.cat([pred_answer, next_tok.unsqueeze(-1)], dim=-1)\n",
    "        pred_context = torch.cat([pred_context, next_tok.unsqueeze(-1)], dim=-1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        # only get embeddings for answer and GT from the model\n",
    "        answer = tokenizer.decode(pred_answer[pred_answer.int()!=50257].int())                # remove padding tokens, <EOC> token remains\n",
    "        pred_out_logits, _ = model.forward({'image': image,'input_ids': pred_context[pred_context!=50257].unsqueeze(0)}, return_embeds=True)\n",
    "\n",
    "    return pred_context, pred_out_logits, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "validation dataset has 405 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 307/405 [12:49<04:30,  2.76s/it]"
     ]
    }
   ],
   "source": [
    "# do validation dataset eval\n",
    "val_loader_iter = iter(val_loader)\n",
    "n = len(val_loader)\n",
    "print(f'validation dataset has {n} samples')\n",
    "\n",
    "preds = torch.tensor([])\n",
    "reals = torch.tensor([])\n",
    "\n",
    "similarity_num = 0\n",
    "identical_num = 0\n",
    "\n",
    "for sample in tqdm(val_loader_iter):\n",
    "    val_img = sample[\"image\"]\n",
    "    pred_context  = torch.tensor([tokenizer.encode(\"<|endoftext|> <image> question: \"+ sample[\"question\"][0] + ' answer:')]) \n",
    "    GT_context  = torch.tensor([tokenizer.encode(\"<|endoftext|> <image> question: \"+ sample[\"question\"][0] + ' answer: ' + sample[\"answer\"][0] + '<EOC>')])\n",
    "    out, pred_out_logits, answer = generate_llogits(val_img, pred_context, model, ntok=20, batch=sample)\n",
    "\n",
    "    # print(f'pred: {pred_out_logits.shape}\\nreal: {real_out_logits.shape}')\n",
    "    pred = torch.mean(pred_out_logits, dim=1)\n",
    "    preds = torch.cat([preds,pred], dim=0)\n",
    "\n",
    "    ans = answer.replace('<EOC>','')\n",
    "\n",
    "    if sample[\"answer\"][0].strip().lower() == ans.strip().lower():\n",
    "        identical_num += 1\n",
    "\n",
    "    multiples = [len(val_answer_embeds.keys()), 1]\n",
    "\n",
    "    b = pred.tile(multiples)\n",
    "\n",
    "    similarity_max = np.NINF\n",
    "    answer = None\n",
    "    for i, key in enumerate(val_answer_embeds.keys()):\n",
    "        similarity = torch.nn.CosineSimilarity()(b[i], val_answer_embeds[key])\n",
    "        if similarity_max < similarity:\n",
    "            similarity_max = similarity\n",
    "            answer = key\n",
    "\n",
    "    if answer.strip().lower() in sample['answer'][0].strip().lower() or sample['answer'][0].strip().lower() in answer.strip().lower() or answer.strip().lower() == sample['answer'][0].strip().lower():\n",
    "        similarity_num += 1\n",
    "    \n",
    "\n",
    "print(f'There were {similarity_num} TPs out of {n}')\n",
    "print(f'There were {identical_num} identical answers out of {n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "validation dataset has 225 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/225 [00:02<10:33,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Splenule\n",
      "Model out :   Right kidney \n",
      "Embed closest answer: Splenule\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/225 [00:05<09:52,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: no\n",
      "Model out :   No \n",
      "Embed closest answer: Normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 3/225 [00:08<10:11,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: no\n",
      "Model out :   No \n",
      "Embed closest answer: Normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/225 [00:11<10:14,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: No\n",
      "Model out :   No \n",
      "Embed closest answer: Vascular\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5/225 [00:13<10:07,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: No\n",
      "Model out :   No \n",
      "Embed closest answer: Vascular\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 6/225 [00:16<10:10,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: necrosis\n",
      "Model out :   Hyperintense lesion \n",
      "Embed closest answer: necrosis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 7/225 [00:19<10:01,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: necrosis\n",
      "Model out :   right parietal lobe \n",
      "Embed closest answer: necrosis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 8/225 [00:22<10:15,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: posteriorly\n",
      "Model out :   The lesion \n",
      "Embed closest answer: posteriorly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 9/225 [00:25<10:13,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: posteriorly\n",
      "Model out :   Right lobe of the liver \n",
      "Embed closest answer: posteriorly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 10/225 [00:27<10:05,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Right\n",
      "Model out :   Right \n",
      "Embed closest answer: Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 11/225 [00:30<10:03,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Right\n",
      "Model out :   No \n",
      "Embed closest answer: Right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 12/225 [00:33<09:37,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Yes\n",
      "Model out :   yes \n",
      "Embed closest answer: sinusitis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 13/225 [00:35<09:18,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Yes\n",
      "Model out :   no \n",
      "Embed closest answer: Yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 14/225 [00:38<09:06,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: YES\n",
      "Model out :   no \n",
      "Embed closest answer: YES\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 15/225 [00:40<08:52,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: The lungs\n",
      "Model out :   CT? <EOQ> answer: CT - CT \n",
      "Embed closest answer: The lungs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 16/225 [00:43<08:44,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Right lung\n",
      "Model out :   Right upper lobe \n",
      "Embed closest answer: Right lung\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 17/225 [00:45<08:34,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Right lung\n",
      "Model out :   right lung \n",
      "Embed closest answer: Right lung\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 18/225 [00:47<08:28,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Yes\n",
      "Model out :   no \n",
      "Embed closest answer: Not sure.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 19/225 [00:50<08:23,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Yes\n",
      "Model out :   yes \n",
      "Embed closest answer: Not sure.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 20/225 [00:52<08:28,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: No\n",
      "Model out :   Yes \n",
      "Embed closest answer: Pneumothorax\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 21/225 [00:55<08:23,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: No\n",
      "Model out :   Yes \n",
      "Embed closest answer: Yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 22/225 [00:57<08:18,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: head/neck CT\n",
      "Model out :   PA \n",
      "Embed closest answer: head/neck CT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 23/225 [01:00<08:14,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Biopsy\n",
      "Model out :   PA \n",
      "Embed closest answer: Biopsy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 24/225 [01:02<08:10,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: metastases, infection/abcess, glioblastoma\n",
      "Model out :   brain fractures \n",
      "Embed closest answer: sinusitis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 25/225 [01:05<08:10,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Toxoplasma, lymphoma, abscesses, other brain tumors\n",
      "Model out :   ring <EOQ> answer: Temporal and medulla \n",
      "Embed closest answer: Toxoplasma, lymphoma, abscesses, other brain tumors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 26/225 [01:07<08:07,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Hemorrhage\n",
      "Model out :   sella \n",
      "Embed closest answer: Hemorrhage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 27/225 [01:09<08:02,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Cancer\n",
      "Model out :   Yes \n",
      "Embed closest answer: Cancer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 28/225 [01:12<08:04,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: ureteral obstruction\n",
      "Model out :   Fat stranding \n",
      "Embed closest answer: ureteral obstruction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 29/225 [01:14<08:01,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: ureteral obstruction\n",
      "Model out :   yes \n",
      "Embed closest answer: ureteral obstruction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 30/225 [01:17<07:58,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: lentiform\n",
      "Model out :   Ring enhancing lesion and surrounding tissue? <EOQ> answer: PRES \n",
      "Embed closest answer: lentiform\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 31/225 [01:19<07:53,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Biconvex\n",
      "Model out :   Basal Ganglia \n",
      "Embed closest answer: Biconvex\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 32/225 [01:22<07:55,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Psoas muscles\n",
      "Model out :   No \n",
      "Embed closest answer: Psoas muscles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 33/225 [01:24<07:51,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Psoas muscles\n",
      "Model out :   Right kidney \n",
      "Embed closest answer: Psoas muscles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 34/225 [01:27<07:46,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: epidural hematoma\n",
      "Model out :   coronal \n",
      "Embed closest answer: epidural hematoma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 35/225 [01:29<07:42,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: sinusitis\n",
      "Model out :   DWI occipital lobe of the brain demonstrates pathology \n",
      "Embed closest answer: sinusitis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 36/225 [01:31<07:39,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: viral\n",
      "Model out :   Yes \n",
      "Embed closest answer: viral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 37/225 [01:34<07:41,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Parasitic\n",
      "Model out :   no \n",
      "Embed closest answer: Parasitic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 38/225 [01:36<07:32,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: No\n",
      "Model out :   yes <EOQ> answer: 7th rib \n",
      "Embed closest answer: C-T ratio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 39/225 [01:39<07:28,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: No\n",
      "Model out :   no \n",
      "Embed closest answer: Normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 40/225 [01:41<07:26,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: If the heart diameter is greater than half the diameter of the thoracic cavity.\n",
      "Model out :   Posterior \n",
      "Embed closest answer: C-T ratio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 41/225 [01:44<07:33,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: C-T ratio\n",
      "Model out :   Left lung field \n",
      "Embed closest answer: C-T ratio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 42/225 [01:46<07:38,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: abcess\n",
      "Model out :   ascites \n",
      "Embed closest answer: abcess\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 43/225 [01:49<07:48,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: abcess\n",
      "Model out :   Atherosclerotic lesion \n",
      "Embed closest answer: abcess\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 44/225 [01:52<07:44,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Bronchiectasis\n",
      "Model out :   Chest \n",
      "Embed closest answer: Bronchiectasis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 45/225 [01:54<07:41,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Thickening of bronchi\n",
      "Model out :   PA \n",
      "Embed closest answer: Thickening of bronchi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 46/225 [01:57<07:47,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: No\n",
      "Model out :   no \n",
      "Embed closest answer: bilateral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 47/225 [02:00<07:56,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: No\n",
      "Model out :   No \n",
      "Embed closest answer: Normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 48/225 [02:02<07:54,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: no\n",
      "Model out :   yes \n",
      "Embed closest answer: No\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 49/225 [02:05<07:54,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: no\n",
      "Model out :   Yes \n",
      "Embed closest answer: No\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 50/225 [02:08<07:57,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: CSF is brightly lit\n",
      "Model out :   Lying \n",
      "Embed closest answer: CSF is brightly lit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 51/225 [02:11<07:57,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Aorta enhancement\n",
      "Model out :   CT with contrast \n",
      "Embed closest answer: Aorta enhancement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 52/225 [02:13<07:45,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Yes\n",
      "Model out :   yes <EOQ> answer: No \n",
      "Embed closest answer: Yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 53/225 [02:16<07:43,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Yes\n",
      "Model out :   No \n",
      "Embed closest answer: CVA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 54/225 [02:19<07:38,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: lateral ventricles\n",
      "Model out :   Right Cerebellum \n",
      "Embed closest answer: lateral ventricles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 55/225 [02:21<07:26,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: lateral ventricles\n",
      "Model out :   Brain \n",
      "Embed closest answer: lateral ventricles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 56/225 [02:23<07:14,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: No\n",
      "Model out :   No \n",
      "Embed closest answer: no\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 57/225 [02:26<07:08,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: No\n",
      "Model out :   no \n",
      "Embed closest answer: no\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 58/225 [02:28<07:02,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: costophrenic angle blunting\n",
      "Model out :   Right side \n",
      "Embed closest answer: Fluid in the pleural space\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 59/225 [02:31<07:19,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Fluid in the pleural space\n",
      "Model out :   cardiomegaly; PA \n",
      "Embed closest answer: Fluid in the pleural space\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 60/225 [02:34<07:22,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: aorta is bright\n",
      "Model out :   CT \n",
      "Embed closest answer: Enhancement of vessels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 61/225 [02:37<07:23,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Enhancement of vessels\n",
      "Model out :   GI \n",
      "Embed closest answer: Enhancement of vessels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 62/225 [02:39<07:07,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: No\n",
      "Model out :   yes \n",
      "Embed closest answer: yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 63/225 [02:42<06:58,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: No\n",
      "Model out :   yes \n",
      "Embed closest answer: No\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 64/225 [02:44<06:55,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Left\n",
      "Model out :   right lobe? <EOQ> answer: right hemidiaphragm \n",
      "Embed closest answer: Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 65/225 [02:47<06:54,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Left\n",
      "Model out :   yes \n",
      "Embed closest answer: Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 66/225 [02:49<06:45,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: genetic\n",
      "Model out :   Yes \n",
      "Embed closest answer: genetic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 67/225 [02:52<06:36,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Vascular\n",
      "Model out :   Yes \n",
      "Embed closest answer: Vascular\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 68/225 [02:54<06:37,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: crescent\n",
      "Model out :   FLAIR \n",
      "Embed closest answer: crescent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 69/225 [02:57<06:35,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Concave\n",
      "Model out :   Subdural hematoma \n",
      "Embed closest answer: Concave\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 70/225 [03:00<06:33,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: No\n",
      "Model out :   no \n",
      "Embed closest answer: abdominal pain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 71/225 [03:02<06:23,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Yes\n",
      "Model out :   no \n",
      "Embed closest answer: abdominal pain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 72/225 [03:04<06:17,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: hydropneumothorax\n",
      "Model out :   pleural effusion \n",
      "Embed closest answer: Infection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 73/225 [03:07<06:11,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: hydropneumothorax\n",
      "Model out :   coronal section \n",
      "Embed closest answer: hydropneumothorax\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 74/225 [03:09<06:08,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Right MCA\n",
      "Model out :   Right temporal lobe \n",
      "Embed closest answer: Right MCA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 75/225 [03:12<06:04,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Right MCA\n",
      "Model out :   The lesion is obscured? <EOQ> answer: Right \n",
      "Embed closest answer: Right MCA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 76/225 [03:14<05:59,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Yes\n",
      "Model out :   yes \n",
      "Embed closest answer: viral/inflammatory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 77/225 [03:17<06:35,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Yes\n",
      "Model out :   No \n",
      "Embed closest answer: CVA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 78/225 [03:20<06:29,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: a catheter\n",
      "Model out :   3rd rib \n",
      "Embed closest answer: a catheter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 79/225 [03:22<06:15,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: a catheter\n",
      "Model out :   right apical bullous enlargement \n",
      "Embed closest answer: bilateral pleural effusion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 80/225 [03:25<06:08,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Yes\n",
      "Model out :   yes \n",
      "Embed closest answer: infiltrative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 81/225 [03:27<06:03,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Yes\n",
      "Model out :   yes \n",
      "Embed closest answer: Pneumothorax\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 82/225 [03:30<05:55,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: yes\n",
      "Model out :   No <EOQ> answer: Yes \n",
      "Embed closest answer: Normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 83/225 [03:32<05:50,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: yes\n",
      "Model out :   yes \n",
      "Embed closest answer: no\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 84/225 [03:35<05:53,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: quadrantopia, aphasia, memory deficit, etc.\n",
      "Model out :   Brain \n",
      "Embed closest answer: sinusitis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 85/225 [03:37<05:50,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Motor weakness, sensory deficits, and left neglect\n",
      "Model out :   Ring enhancing lesions located in the right temporal horn of this lesion? <EOQ> answer: Calc\n",
      "Embed closest answer: Motor weakness, sensory deficits, and left neglect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 86/225 [03:40<05:51,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: No\n",
      "Model out :   Yes \n",
      "Embed closest answer: hydropneumothorax\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 87/225 [03:42<05:47,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: No\n",
      "Model out :   No \n",
      "Embed closest answer: Sharp costophrenic angles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 88/225 [03:45<05:46,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: viral/inflammatory\n",
      "Model out :   Prior injury \n",
      "Embed closest answer: viral/inflammatory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 89/225 [03:47<05:46,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: CVA\n",
      "Model out :   R frontal lobe \n",
      "Embed closest answer: CVA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 90/225 [03:50<05:45,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: In the cortex and basal ganglia bilaterally\n",
      "Model out :   right parietal lobe? <EOQ> answer: right parietal lobe \n",
      "Embed closest answer: In the cortex and basal ganglia bilaterally\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 91/225 [03:53<05:55,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: In the cortex and basal ganglia bilaterally\n",
      "Model out :   left ACA: left temporal lobe, right basal ganglia, left side of the right and right occ\n",
      "Embed closest answer: In the cortex and basal ganglia bilaterally\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 92/225 [03:56<06:11,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: No\n",
      "Model out :   Yes \n",
      "Embed closest answer: No\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 93/225 [03:59<06:06,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: No\n",
      "Model out :   Yes \n",
      "Embed closest answer: No\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 94/225 [04:01<05:54,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: no\n",
      "Model out :   Yes \n",
      "Embed closest answer: no\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 95/225 [04:04<05:40,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: no\n",
      "Model out :   Yes \n",
      "Embed closest answer: no\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 96/225 [04:06<05:31,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: left lobe mass 1.5 x 1.8 cm\n",
      "Model out :   Man <EOQ> answer: PA \n",
      "Embed closest answer: Infection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 97/225 [04:09<05:24,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: left lobe mass 1.5 x 1.8 cm\n",
      "Model out :   Left Apical Pneumothorax \n",
      "Embed closest answer: Right paratracheal mass lesion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 98/225 [04:11<05:23,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Not sure\n",
      "Model out :   Ring-enhancing \n",
      "Embed closest answer: Not sure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 99/225 [04:14<05:22,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Pituitary fossa\n",
      "Model out :   Bilateral cerebellum \n",
      "Embed closest answer: Pituitary fossa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 100/225 [04:16<05:20,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: nephroblastomatosis\n",
      "Model out :   5th rib \n",
      "Embed closest answer: nephroblastomatosis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 101/225 [04:19<05:13,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: nephroblastomatosis\n",
      "Model out :   Suparachnoid Muscle \n",
      "Embed closest answer: nephroblastomatosis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 102/225 [04:21<05:15,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Location of the contrast?\n",
      "Model out :   Diverticuli in the small bowel loops is located in this image? <EOQ> answer: Cirrh\n",
      "Embed closest answer: Location of the contrast?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 103/225 [04:24<05:14,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Haustra\n",
      "Model out :   Diverticulomax and inferior vena cava and IV \n",
      "Embed closest answer: Haustra\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 104/225 [04:27<05:14,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Not sure\n",
      "Model out :   right sided pleural effusion \n",
      "Embed closest answer: Sharp costophrenic angles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 105/225 [04:29<05:11,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Maybe\n",
      "Model out :   yes \n",
      "Embed closest answer: Biopsy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 106/225 [04:32<05:07,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: contrast\n",
      "Model out :   The liver \n",
      "Embed closest answer: contrast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 107/225 [04:34<05:01,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: contrast\n",
      "Model out :   5th rib \n",
      "Embed closest answer: contrast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 108/225 [04:37<04:55,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: RUQ pain, jaundice,weight loss?\n",
      "Model out :   GI \n",
      "Embed closest answer: abdominal pain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 109/225 [04:39<04:49,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: abdominal pain\n",
      "Model out :   Abdomen with IV \n",
      "Embed closest answer: abdominal pain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 110/225 [04:42<04:45,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: pleural plaques\n",
      "Model out :   It is the tip of the body \n",
      "Embed closest answer: pleural plaques\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 111/225 [04:44<04:45,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: pleural plaques\n",
      "Model out :   nodules \n",
      "Embed closest answer: pleural plaques\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 112/225 [04:47<04:41,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Air?\n",
      "Model out :   Cirrhosis? <EOQ> answer: Left \n",
      "Embed closest answer: Air?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 113/225 [04:49<04:35,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: haustra\n",
      "Model out :   Yes \n",
      "Embed closest answer: haustra\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 114/225 [04:51<04:35,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Trace the gallbladder emptying?\n",
      "Model out :   5th of these body is the pancreas \n",
      "Embed closest answer: Trace the gallbladder emptying?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 115/225 [04:54<04:48,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: cystic duct is more tortuous\n",
      "Model out :   5 \n",
      "Embed closest answer: cystic duct is more tortuous\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 116/225 [04:57<04:50,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Tumors, gallstones\n",
      "Model out :   Pericholecystic tissue \n",
      "Embed closest answer: Tumors, gallstones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 117/225 [05:00<04:46,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Stones, cancer, infection, anatomic variants\n",
      "Model out :   kidney and vein \n",
      "Embed closest answer: Stones, cancer, infection, anatomic variants\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 118/225 [05:02<04:38,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Gray matter\n",
      "Model out :   Yes \n",
      "Embed closest answer: Gray matter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 119/225 [05:05<04:31,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Gray matter\n",
      "Model out :   R frontal lobe \n",
      "Embed closest answer: Gray matter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 120/225 [05:07<04:28,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Bilateral lungs\n",
      "Model out :   Right lung field \n",
      "Embed closest answer: Bilateral lungs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 121/225 [05:10<04:21,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Bilateral lungs\n",
      "Model out :   Right lung \n",
      "Embed closest answer: Bilateral lungs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 122/225 [05:12<04:17,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: yes\n",
      "Model out :   No \n",
      "Embed closest answer: genetic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 123/225 [05:15<04:15,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: No\n",
      "Model out :   no \n",
      "Embed closest answer: Yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 124/225 [05:17<04:13,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Not sure\n",
      "Model out :   Cirrhosis is present primarily? <EOQ> answer: Cirrhosis \n",
      "Embed closest answer: Air?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 125/225 [05:20<04:09,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: plicae circulares\n",
      "Model out :   Pancreas \n",
      "Embed closest answer: haustra\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 126/225 [05:22<04:08,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: No\n",
      "Model out :   Yes \n",
      "Embed closest answer: Normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 127/225 [05:25<04:04,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: No\n",
      "Model out :   Yes \n",
      "Embed closest answer: Normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 128/225 [05:27<04:00,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: More acute means more inflammation-leading to enhancement?\n",
      "Model out :   FLAIR \n",
      "Embed closest answer: More acute means more inflammation-leading to enhancement?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 129/225 [05:30<03:58,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Less enhancement\n",
      "Model out :   right temporal lobe \n",
      "Embed closest answer: Less enhancement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 130/225 [05:32<03:55,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: CSF is white.\n",
      "Model out :   Brain injury \n",
      "Embed closest answer: CSF is white.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 131/225 [05:35<03:51,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: White versus grey matter brightness\n",
      "Model out :   axial \n",
      "Embed closest answer: White versus grey matter brightness\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 132/225 [05:37<03:54,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Adenopathy\n",
      "Model out :   Right Apical Pneumothorax \n",
      "Embed closest answer: Right paratracheal mass lesion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 133/225 [05:40<03:48,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Infection\n",
      "Model out :   right upper lobe lung field \n",
      "Embed closest answer: Infection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 134/225 [05:42<03:43,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Maybe\n",
      "Model out :   no \n",
      "Embed closest answer: Maybe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 135/225 [05:44<03:40,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Yes\n",
      "Model out :   Yes \n",
      "Embed closest answer: Maybe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 136/225 [05:47<03:42,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Paratracheal area\n",
      "Model out :   left lower lung field, just just on either side? <EOQ> answer: Right \n",
      "Embed closest answer: Paratracheal area\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 137/225 [05:49<03:36,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Paratracheal area\n",
      "Model out :   right hemidiaphragm \n",
      "Embed closest answer: Paratracheal area\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 138/225 [05:52<03:34,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Not sure.\n",
      "Model out :   yes \n",
      "Embed closest answer: Not sure.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 139/225 [05:54<03:32,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: 5%\n",
      "Model out :   Right kidney \n",
      "Embed closest answer: 5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 140/225 [05:57<03:30,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Rounded, well-defined pulmonary nodules varying in size and pattern\n",
      "Model out :   Right lung field more than half of the thorax seen in this image? <EOQ> answer: right\n",
      "Embed closest answer: Rounded, well-defined pulmonary nodules varying in size and pattern\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 141/225 [05:59<03:28,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: pulmonary nodules\n",
      "Model out :   right sided pleural effusion and right side \n",
      "Embed closest answer: Right paratracheal mass lesion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 142/225 [06:02<03:24,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: bilateral pleural effusion\n",
      "Model out :   Xray \n",
      "Embed closest answer: a catheter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 143/225 [06:04<03:22,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: bilateral pleural effusion\n",
      "Model out :   Chest X-ray \n",
      "Embed closest answer: bilateral pleural effusion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 144/225 [06:07<03:18,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: No\n",
      "Model out :   Yes \n",
      "Embed closest answer: Normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 145/225 [06:09<03:15,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: No\n",
      "Model out :   No \n",
      "Embed closest answer: Normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 146/225 [06:12<03:14,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: No\n",
      "Model out :   No \n",
      "Embed closest answer: No\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 147/225 [06:14<03:11,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: No\n",
      "Model out :   No \n",
      "Embed closest answer: No\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 148/225 [06:17<03:12,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: basal ganglia (caudate and putamen)\n",
      "Model out :   sella \n",
      "Embed closest answer: basal ganglia (caudate and putamen)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 149/225 [06:19<03:12,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: basal ganglia (caudate and putamen)\n",
      "Model out :   right thalamus \n",
      "Embed closest answer: basal ganglia (caudate and putamen)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 150/225 [06:22<03:14,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Cerebellum\n",
      "Model out :   Maxillary sinus abdominis \n",
      "Embed closest answer: Cerebellum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 151/225 [06:24<03:09,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Cerebellum\n",
      "Model out :   Necrotic ventricles \n",
      "Embed closest answer: Cerebellum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 152/225 [06:27<03:08,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: cardiopulmonary\n",
      "Model out :   cardiomegaly? <EOQ> answer: pulmonary artery \n",
      "Embed closest answer: cardiopulmonary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 153/225 [06:30<03:01,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: cardiopulmonary\n",
      "Model out :   coronal \n",
      "Embed closest answer: cardiopulmonary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 154/225 [06:32<02:56,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: yes\n",
      "Model out :   Yes \n",
      "Embed closest answer: yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 155/225 [06:34<02:52,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: yes\n",
      "Model out :   No \n",
      "Embed closest answer: yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 156/225 [06:37<02:50,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Semi-upright position\n",
      "Model out :   PA \n",
      "Embed closest answer: Semi-upright position\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 157/225 [06:39<02:50,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Semi-upright position\n",
      "Model out :   PA \n",
      "Embed closest answer: Semi-upright position\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 158/225 [06:42<02:50,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: No\n",
      "Model out :   No \n",
      "Embed closest answer: Yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 159/225 [06:45<02:49,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Yes\n",
      "Model out :   Yes \n",
      "Embed closest answer: Yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 160/225 [06:47<02:47,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Sharp costophrenic angles\n",
      "Model out :   Yes \n",
      "Embed closest answer: Sharp costophrenic angles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 161/225 [06:50<02:48,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Sharp costophrenic angles\n",
      "Model out :   pulmonary effusion \n",
      "Embed closest answer: Sharp costophrenic angles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 162/225 [06:53<02:47,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: No\n",
      "Model out :   White matter \n",
      "Embed closest answer: Diffuse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 163/225 [06:55<02:44,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: No\n",
      "Model out :   Yes \n",
      "Embed closest answer: sinusitis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 164/225 [06:58<02:43,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: No\n",
      "Model out :   No \n",
      "Embed closest answer: No\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 165/225 [07:01<02:37,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: No\n",
      "Model out :   yes \n",
      "Embed closest answer: Yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 166/225 [07:03<02:34,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Right parietal\n",
      "Model out :   No \n",
      "Embed closest answer: Right parietal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 167/225 [07:06<02:33,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Right parietal\n",
      "Model out :   Right cerebellum \n",
      "Embed closest answer: Right parietal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 168/225 [07:09<02:33,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: horsehoe kidney\n",
      "Model out :   Contrast \n",
      "Embed closest answer: horsehoe kidney\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 169/225 [07:12<02:33,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: horsehoe kidney\n",
      "Model out :   Blind \n",
      "Embed closest answer: horsehoe kidney\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 170/225 [07:14<02:30,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Diffuse\n",
      "Model out :   right temporal lobe \n",
      "Embed closest answer: Diffuse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 171/225 [07:17<02:25,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Diffuse\n",
      "Model out :   right temporal lobe \n",
      "Embed closest answer: Diffuse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 172/225 [07:19<02:20,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Posterior lung seen in the image section\n",
      "Model out :   Splenule \n",
      "Embed closest answer: Pneumothorax\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 173/225 [07:22<02:14,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Pneumothorax\n",
      "Model out :   hepatocellular carcioma \n",
      "Embed closest answer: Pneumothorax\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 174/225 [07:24<02:09,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: No\n",
      "Model out :   No \n",
      "Embed closest answer: No\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 175/225 [07:27<02:06,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: No\n",
      "Model out :   Midline, Left temporal lobe and left temporal lobe and lateral ventricular lateral ventricle \n",
      "Embed closest answer: Cortical ribbon of right occipital lobe with extension into right posterior temporal lobe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 176/225 [07:29<02:03,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: bilateral\n",
      "Model out :   yes \n",
      "Embed closest answer: bilateral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 177/225 [07:32<02:03,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: both sides\n",
      "Model out :   No \n",
      "Embed closest answer: both sides\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 178/225 [07:35<02:01,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Exterior\n",
      "Model out :   No \n",
      "Embed closest answer: Exterior\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 179/225 [07:37<02:01,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Outside\n",
      "Model out :   No \n",
      "Embed closest answer: Outside\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 180/225 [07:40<01:59,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: blunting of the costophrenic angle, loss of the right hemidiaphragm and right heart border\n",
      "Model out :   right lung \n",
      "Embed closest answer: Right lung\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 181/225 [07:43<01:56,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: blunting of the costophrenic angle, loss of the right hemidiaphragm and right heart border\n",
      "Model out :   Left \n",
      "Embed closest answer: Right lung\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 182/225 [07:45<01:51,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Increased opacity in the left retrocardiac region\n",
      "Model out :   yes \n",
      "Embed closest answer: bilateral pleural effusion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 183/225 [07:48<01:48,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Increased opacity in the left retrocardiac region\n",
      "Model out :   right lung base \n",
      "Embed closest answer: bilateral pleural effusion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 184/225 [07:50<01:46,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Right paratracheal mass lesion\n",
      "Model out :   cardiomegaly with pulmonary edema \n",
      "Embed closest answer: hydropneumothorax\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 185/225 [07:53<01:44,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Right paratracheal mass lesion\n",
      "Model out :   Coronal \n",
      "Embed closest answer: bilateral pleural effusion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 186/225 [07:56<01:47,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: ring-enhancing lesion\n",
      "Model out :   MRI - T2 weighted, and FLAIR \n",
      "Embed closest answer: ring-enhancing lesion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 187/225 [07:59<01:43,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: ring-enhancing lesion\n",
      "Model out :   right temporal lobe of the right hemisphere of the brain? <EOQ> answer: Right frontal lobe, basal\n",
      "Embed closest answer: lateral ventricles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 188/225 [08:01<01:40,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: No\n",
      "Model out :   No \n",
      "Embed closest answer: Yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 189/225 [08:04<01:37,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Yes\n",
      "Model out :   No \n",
      "Embed closest answer: Yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 190/225 [08:07<01:34,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: No\n",
      "Model out :   yes \n",
      "Embed closest answer: yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 191/225 [08:10<01:32,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: No\n",
      "Model out :   yes \n",
      "Embed closest answer: yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 192/225 [08:12<01:27,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Yes\n",
      "Model out :   Yes \n",
      "Embed closest answer: Normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 193/225 [08:14<01:22,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Yes\n",
      "Model out :   yes \n",
      "Embed closest answer: Normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 194/225 [08:17<01:20,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: It is enlarged with prominence of the aortic knob\n",
      "Model out :   PA \n",
      "Embed closest answer: C-T ratio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 195/225 [08:20<01:17,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: It is enlarged with prominence of the aortic knob\n",
      "Model out :   PA \n",
      "Embed closest answer: bilateral pleural effusion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 196/225 [08:22<01:16,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Well-circumscribed\n",
      "Model out :   The pancreas \n",
      "Embed closest answer: Well-circumscribed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 197/225 [08:25<01:14,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: exophytic cyst\n",
      "Model out :   Pancreas \n",
      "Embed closest answer: exophytic cyst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 198/225 [08:28<01:10,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Shrunken and nodular\n",
      "Model out :   Axial \n",
      "Embed closest answer: Shrunken and nodular\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 199/225 [08:30<01:07,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Shrunken and nodular\n",
      "Model out :   With the image is the liver? <EOQ> answer: The liver \n",
      "Embed closest answer: Shrunken and nodular\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 200/225 [08:33<01:03,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Infarcts\n",
      "Model out :   right parietal lobe \n",
      "Embed closest answer: Infarcts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 201/225 [08:35<01:01,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: embolus\n",
      "Model out :   Brain occlusion \n",
      "Embed closest answer: embolus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 202/225 [08:38<01:00,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: No\n",
      "Model out :   yes \n",
      "Embed closest answer: No\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 203/225 [08:40<00:56,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: No\n",
      "Model out :   yes \n",
      "Embed closest answer: yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 204/225 [08:43<00:53,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Yes\n",
      "Model out :   Yes \n",
      "Embed closest answer: Normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 205/225 [08:45<00:50,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Yes\n",
      "Model out :   yes \n",
      "Embed closest answer: Normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 206/225 [08:48<00:48,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: No\n",
      "Model out :   Yes \n",
      "Embed closest answer: No\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 207/225 [08:51<00:47,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: No\n",
      "Model out :   yes \n",
      "Embed closest answer: No\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 208/225 [08:54<00:48,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Cortical ribbon of right occipital lobe with extension into right posterior temporal lobe\n",
      "Model out :   Right cerebellum \n",
      "Embed closest answer: Diffuse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 209/225 [08:57<00:43,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Cortical ribbon of right occipital lobe with extension into right posterior temporal lobe\n",
      "Model out :   Pineal gland \n",
      "Embed closest answer: Diffuse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 210/225 [08:59<00:39,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Irregular\n",
      "Model out :   Yes \n",
      "Embed closest answer: Irregular\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 211/225 [09:02<00:36,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: infiltrative\n",
      "Model out :   The lesion \n",
      "Embed closest answer: infiltrative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 212/225 [09:04<00:33,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: 12\n",
      "Model out :   one side is similar with what side shift \n",
      "Embed closest answer: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 213/225 [09:07<00:30,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: 12\n",
      "Model out :   3th rib fractures \n",
      "Embed closest answer: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 214/225 [09:09<00:27,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: No\n",
      "Model out :   no \n",
      "Embed closest answer: Yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 215/225 [09:12<00:25,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: No\n",
      "Model out :   No \n",
      "Embed closest answer: Vascular\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 216/225 [09:15<00:24,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: On top of the patient\n",
      "Model out :   Yes \n",
      "Embed closest answer: On top of the patient\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 217/225 [09:18<00:22,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer:  superficial to the patient's skin\n",
      "Model out :   No \n",
      "Embed closest answer:  superficial to the patient's skin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 218/225 [09:20<00:19,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Yes\n",
      "Model out :   No \n",
      "Embed closest answer: Normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 219/225 [09:23<00:16,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Normal\n",
      "Model out :   No \n",
      "Embed closest answer: Normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 220/225 [09:26<00:13,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: FLAIR\n",
      "Model out :   FLAIR \n",
      "Embed closest answer: FLAIR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 221/225 [09:28<00:10,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: FLAIR\n",
      "Model out :   No \n",
      "Embed closest answer: FLAIR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 222/225 [09:31<00:07,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Yes\n",
      "Model out :   yes <EOQ> answer: Female \n",
      "Embed closest answer: Biopsy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 223/225 [09:33<00:05,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Yes\n",
      "Model out :   PA \n",
      "Embed closest answer: cardiopulmonary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 224/225 [09:36<00:02,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Nucleus Pulposus\n",
      "Model out :   fat \n",
      "Embed closest answer: Nucleus Pulposus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [09:38<00:00,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [09:39<00:00,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Answer: Nucleus Pulposus\n",
      "Model out :   Fat fluid \n",
      "Embed closest answer: Nucleus Pulposus\n",
      "There were 154 TPs out of 225\n",
      "There were 37 identical answers out of 225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# do validation dataset eval\n",
    "test_loader_iter = iter(test_loader)\n",
    "n = len(test_loader)\n",
    "print(f'validation dataset has {n} samples')\n",
    "\n",
    "preds = torch.tensor([])\n",
    "reals = torch.tensor([])\n",
    "\n",
    "similarity_num = 0\n",
    "identical_num = 0\n",
    "\n",
    "for sample in tqdm(test_loader_iter):\n",
    "    val_img = sample[\"image\"]\n",
    "    pred_context  = torch.tensor([tokenizer.encode(\"<|endoftext|> <image> question: \"+ sample[\"question\"][0] + ' answer:')]) \n",
    "    GT_context  = torch.tensor([tokenizer.encode(\"<|endoftext|> <image> question: \"+ sample[\"question\"][0] + ' answer: ' + sample[\"answer\"][0] + '<EOC>')])\n",
    "    out, pred_out_logits, answer = generate_llogits(val_img, pred_context, model, ntok=20, batch=sample)\n",
    "\n",
    "    # print(f'pred: {pred_out_logits.shape}\\nreal: {real_out_logits.shape}')\n",
    "    pred = torch.mean(pred_out_logits, dim=1)\n",
    "\n",
    "    ans = answer.replace('<EOC>','')\n",
    "\n",
    "    if sample[\"answer\"][0].strip().lower() == ans.strip().lower():\n",
    "        identical_num += 1\n",
    "\n",
    "    multiples = [len(test_answer_embeds.keys()), 1]\n",
    "\n",
    "    b = pred.tile(multiples)\n",
    "\n",
    "    similarity_max = np.NINF\n",
    "    answer = None\n",
    "    for i, key in enumerate(test_answer_embeds.keys()):\n",
    "        similarity = torch.nn.CosineSimilarity()(b[i], test_answer_embeds[key])\n",
    "        if similarity_max < similarity:\n",
    "            similarity_max = similarity\n",
    "            answer = key\n",
    "\n",
    "    if answer.strip().lower() in sample['answer'][0].strip().lower() or sample['answer'][0].strip().lower() in answer.strip().lower() or answer.strip().lower() == sample['answer'][0].strip().lower():\n",
    "        similarity_num += 1\n",
    "    \n",
    "    print(\"GT Answer: \" + sample[\"answer\"][0])\n",
    "    print(\"Model out : \", ans)\n",
    "    print(f'Embed closest answer: {answer}')\n",
    "\n",
    "print(f'There were {similarity_num} TPs out of {n}')\n",
    "print(f'There were {identical_num} identical answers out of {n}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('mlmi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "30ec110bc924a9e139919a87e1ff85100b6c769b1dd45b8d281b6aff673f8e03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
