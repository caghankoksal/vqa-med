{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caghankoksal/miniforge3/envs/torch-nightly/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from flamingo_pytorch import PerceiverResampler\n",
    "\n",
    "perceive = PerceiverResampler(\n",
    "    dim = 1024,\n",
    "    depth = 2,\n",
    "    dim_head = 64,\n",
    "    heads = 8,\n",
    "    num_latents = 64,    # the number of latents to shrink your media sequence to, perceiver style\n",
    "    num_time_embeds = 4  # say you have 4 images maximum in your dialogue\n",
    ")\n",
    "\n",
    "medias = torch.randn(1, 2, 256, 1024) # (batch, time, sequence length, dimension)\n",
    "perceived = perceive(medias) # (1, 2, 64, 1024) - (batch, time, num latents, dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from flamingo_pytorch import GatedCrossAttentionBlock\n",
    "\n",
    "cross_attn = GatedCrossAttentionBlock(\n",
    "    dim = 1024,\n",
    "    dim_head = 64,\n",
    "    heads = 8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GatedCrossAttentionBlock(\n",
       "  (attn): MaskedCrossAttention(\n",
       "    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (to_q): Linear(in_features=1024, out_features=512, bias=False)\n",
       "    (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "    (to_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "  )\n",
       "  (ff): Sequential(\n",
       "    (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "    (2): GELU(approximate=none)\n",
       "    (3): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = torch.randn(1, 512, 1024)\n",
    "perceived = torch.randn(1, 2, 64, 1024)\n",
    "media_locations = torch.randint(0, 2, (1, 512)).bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 1024])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = cross_attn(\n",
    "    text,\n",
    "    perceived,\n",
    "    media_locations = media_locations\n",
    ")\n",
    "text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vit_pytorch.vit import ViT\n",
    "from vit_pytorch.extractor import Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit = ViT(\n",
    "    image_size = 256,\n",
    "    patch_size = 32,\n",
    "    num_classes = 1000,\n",
    "    dim = 1024,\n",
    "    depth = 6,\n",
    "    heads = 16,\n",
    "    mlp_dim = 2048,\n",
    "    dropout = 0.1,\n",
    "    emb_dropout = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vit = Extractor(vit, return_embeddings_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from flamingo_pytorch import FlamingoPaLM\n",
    "\n",
    "# a PaLM language model, the 540 billion parameter model from google that shows signs of general intelligence\n",
    "\n",
    "flamingo_palm = FlamingoPaLM(\n",
    "    num_tokens = 20000,          # number of tokens\n",
    "    dim = 1024,                  # dimensions\n",
    "    depth = 12,                  # depth\n",
    "    heads = 8,                   # attention heads\n",
    "    dim_head = 64,               # dimension per attention head\n",
    "    img_encoder = vit,           # plugin your image encoder (this can be optional if you pass in the image embeddings separately, but probably want to train end to end given the perceiver resampler)\n",
    "    media_token_id = 3,          # the token id representing the [media] or [image]\n",
    "    cross_attn_every = 3,        # how often to cross attend\n",
    "    perceiver_num_latents = 64,  # perceiver number of latents, should be smaller than the sequence length of the image tokens\n",
    "    perceiver_depth = 2          # perceiver resampler depth\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FlamingoPaLM(\n",
       "  (token_emb): Embedding(20000, 1024)\n",
       "  (img_encoder): Extractor(\n",
       "    (vit): ViT(\n",
       "      (to_patch_embedding): Sequential(\n",
       "        (0): Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=32, p2=32)\n",
       "        (1): Linear(in_features=3072, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (transformer): Transformer(\n",
       "        (layers): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): PreNorm(\n",
       "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): Attention(\n",
       "                (attend): Softmax(dim=-1)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (1): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): PreNorm(\n",
       "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "                  (1): GELU(approximate=none)\n",
       "                  (2): Dropout(p=0.1, inplace=False)\n",
       "                  (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "                  (4): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): ModuleList(\n",
       "            (0): PreNorm(\n",
       "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): Attention(\n",
       "                (attend): Softmax(dim=-1)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (1): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): PreNorm(\n",
       "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "                  (1): GELU(approximate=none)\n",
       "                  (2): Dropout(p=0.1, inplace=False)\n",
       "                  (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "                  (4): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): ModuleList(\n",
       "            (0): PreNorm(\n",
       "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): Attention(\n",
       "                (attend): Softmax(dim=-1)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (1): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): PreNorm(\n",
       "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "                  (1): GELU(approximate=none)\n",
       "                  (2): Dropout(p=0.1, inplace=False)\n",
       "                  (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "                  (4): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): ModuleList(\n",
       "            (0): PreNorm(\n",
       "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): Attention(\n",
       "                (attend): Softmax(dim=-1)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (1): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): PreNorm(\n",
       "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "                  (1): GELU(approximate=none)\n",
       "                  (2): Dropout(p=0.1, inplace=False)\n",
       "                  (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "                  (4): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (4): ModuleList(\n",
       "            (0): PreNorm(\n",
       "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): Attention(\n",
       "                (attend): Softmax(dim=-1)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (1): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): PreNorm(\n",
       "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "                  (1): GELU(approximate=none)\n",
       "                  (2): Dropout(p=0.1, inplace=False)\n",
       "                  (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "                  (4): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (5): ModuleList(\n",
       "            (0): PreNorm(\n",
       "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): Attention(\n",
       "                (attend): Softmax(dim=-1)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (1): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): PreNorm(\n",
       "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "                  (1): GELU(approximate=none)\n",
       "                  (2): Dropout(p=0.1, inplace=False)\n",
       "                  (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "                  (4): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (to_latent): Identity()\n",
       "      (mlp_head): Sequential(\n",
       "        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): Linear(in_features=1024, out_features=1000, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (perceiver_resampler): PerceiverResampler(\n",
       "    (layers): ModuleList(\n",
       "      (0): ModuleList(\n",
       "        (0): PerceiverAttention(\n",
       "          (norm_media): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm_latents): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (to_q): Linear(in_features=1024, out_features=512, bias=False)\n",
       "          (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (to_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (2): GELU(approximate=none)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (1): ModuleList(\n",
       "        (0): PerceiverAttention(\n",
       "          (norm_media): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm_latents): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (to_q): Linear(in_features=1024, out_features=512, bias=False)\n",
       "          (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (to_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (2): GELU(approximate=none)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (layers): ModuleList(\n",
       "    (0): ModuleList(\n",
       "      (0): Residual(\n",
       "        (fn): ParallelTransformerBlock(\n",
       "          (norm): LayerNorm()\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (fused_attn_ff_proj): Linear(in_features=1024, out_features=8832, bias=False)\n",
       "          (attn_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          (ff_out): Sequential(\n",
       "            (0): SwiGLU()\n",
       "            (1): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): GatedCrossAttentionBlock(\n",
       "        (attn): MaskedCrossAttention(\n",
       "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (to_q): Linear(in_features=1024, out_features=512, bias=False)\n",
       "          (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (to_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "        )\n",
       "        (ff): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (2): GELU(approximate=none)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): ModuleList(\n",
       "      (0): Residual(\n",
       "        (fn): ParallelTransformerBlock(\n",
       "          (norm): LayerNorm()\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (fused_attn_ff_proj): Linear(in_features=1024, out_features=8832, bias=False)\n",
       "          (attn_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          (ff_out): Sequential(\n",
       "            (0): SwiGLU()\n",
       "            (1): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): None\n",
       "    )\n",
       "    (2): ModuleList(\n",
       "      (0): Residual(\n",
       "        (fn): ParallelTransformerBlock(\n",
       "          (norm): LayerNorm()\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (fused_attn_ff_proj): Linear(in_features=1024, out_features=8832, bias=False)\n",
       "          (attn_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          (ff_out): Sequential(\n",
       "            (0): SwiGLU()\n",
       "            (1): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): None\n",
       "    )\n",
       "    (3): ModuleList(\n",
       "      (0): Residual(\n",
       "        (fn): ParallelTransformerBlock(\n",
       "          (norm): LayerNorm()\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (fused_attn_ff_proj): Linear(in_features=1024, out_features=8832, bias=False)\n",
       "          (attn_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          (ff_out): Sequential(\n",
       "            (0): SwiGLU()\n",
       "            (1): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): GatedCrossAttentionBlock(\n",
       "        (attn): MaskedCrossAttention(\n",
       "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (to_q): Linear(in_features=1024, out_features=512, bias=False)\n",
       "          (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (to_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "        )\n",
       "        (ff): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (2): GELU(approximate=none)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): ModuleList(\n",
       "      (0): Residual(\n",
       "        (fn): ParallelTransformerBlock(\n",
       "          (norm): LayerNorm()\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (fused_attn_ff_proj): Linear(in_features=1024, out_features=8832, bias=False)\n",
       "          (attn_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          (ff_out): Sequential(\n",
       "            (0): SwiGLU()\n",
       "            (1): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): None\n",
       "    )\n",
       "    (5): ModuleList(\n",
       "      (0): Residual(\n",
       "        (fn): ParallelTransformerBlock(\n",
       "          (norm): LayerNorm()\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (fused_attn_ff_proj): Linear(in_features=1024, out_features=8832, bias=False)\n",
       "          (attn_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          (ff_out): Sequential(\n",
       "            (0): SwiGLU()\n",
       "            (1): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): None\n",
       "    )\n",
       "    (6): ModuleList(\n",
       "      (0): Residual(\n",
       "        (fn): ParallelTransformerBlock(\n",
       "          (norm): LayerNorm()\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (fused_attn_ff_proj): Linear(in_features=1024, out_features=8832, bias=False)\n",
       "          (attn_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          (ff_out): Sequential(\n",
       "            (0): SwiGLU()\n",
       "            (1): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): GatedCrossAttentionBlock(\n",
       "        (attn): MaskedCrossAttention(\n",
       "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (to_q): Linear(in_features=1024, out_features=512, bias=False)\n",
       "          (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (to_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "        )\n",
       "        (ff): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (2): GELU(approximate=none)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): ModuleList(\n",
       "      (0): Residual(\n",
       "        (fn): ParallelTransformerBlock(\n",
       "          (norm): LayerNorm()\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (fused_attn_ff_proj): Linear(in_features=1024, out_features=8832, bias=False)\n",
       "          (attn_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          (ff_out): Sequential(\n",
       "            (0): SwiGLU()\n",
       "            (1): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): None\n",
       "    )\n",
       "    (8): ModuleList(\n",
       "      (0): Residual(\n",
       "        (fn): ParallelTransformerBlock(\n",
       "          (norm): LayerNorm()\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (fused_attn_ff_proj): Linear(in_features=1024, out_features=8832, bias=False)\n",
       "          (attn_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          (ff_out): Sequential(\n",
       "            (0): SwiGLU()\n",
       "            (1): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): None\n",
       "    )\n",
       "    (9): ModuleList(\n",
       "      (0): Residual(\n",
       "        (fn): ParallelTransformerBlock(\n",
       "          (norm): LayerNorm()\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (fused_attn_ff_proj): Linear(in_features=1024, out_features=8832, bias=False)\n",
       "          (attn_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          (ff_out): Sequential(\n",
       "            (0): SwiGLU()\n",
       "            (1): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): GatedCrossAttentionBlock(\n",
       "        (attn): MaskedCrossAttention(\n",
       "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (to_q): Linear(in_features=1024, out_features=512, bias=False)\n",
       "          (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (to_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "        )\n",
       "        (ff): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (2): GELU(approximate=none)\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): ModuleList(\n",
       "      (0): Residual(\n",
       "        (fn): ParallelTransformerBlock(\n",
       "          (norm): LayerNorm()\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (fused_attn_ff_proj): Linear(in_features=1024, out_features=8832, bias=False)\n",
       "          (attn_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          (ff_out): Sequential(\n",
       "            (0): SwiGLU()\n",
       "            (1): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): None\n",
       "    )\n",
       "    (11): ModuleList(\n",
       "      (0): Residual(\n",
       "        (fn): ParallelTransformerBlock(\n",
       "          (norm): LayerNorm()\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (fused_attn_ff_proj): Linear(in_features=1024, out_features=8832, bias=False)\n",
       "          (attn_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          (ff_out): Sequential(\n",
       "            (0): SwiGLU()\n",
       "            (1): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): None\n",
       "    )\n",
       "  )\n",
       "  (to_logits): Sequential(\n",
       "    (0): LayerNorm()\n",
       "    (1): Linear(in_features=1024, out_features=20000, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flamingo_palm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text shape :   torch.Size([2, 512])\n",
      "Palm logits shape :  torch.Size([2, 512, 20000])\n"
     ]
    }
   ],
   "source": [
    "# train your PaLM as usual\n",
    "\n",
    "text = torch.randint(0, 20000, (2, 512))\n",
    "print(\"text shape :  \",text.shape)\n",
    "\n",
    "palm_logits = flamingo_palm(text)\n",
    "print(\"Palm logits shape : \",palm_logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after much training off the regular PaLM logits\n",
    "# now you are ready to train Flamingo + PaLM\n",
    "# by passing in images, it automatically freezes everything but the perceiver and cross attention blocks, as in the paper\n",
    "\n",
    "dialogue = torch.randint(0, 20000, (4, 512))\n",
    "images = torch.randn(4, 2, 3, 256, 256)\n",
    "\n",
    "flamingo_logits = flamingo_palm(dialogue, images)\n",
    "\n",
    "# do your usual cross entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/Users/caghankoksal/Desktop/SS2022/emic-vqa/')\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import _pickle as cPickle\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "\n",
    "from src.datasets.vq_rad_dataset import VQ_Rad_Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = '/Users/caghankoksal/Desktop/SS2022/emic-vqa/data/external/data_RAD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = VQ_Rad_Dataset(root=dataroot, transform=transforms.Compose([\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.Resize((224,224)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]),\n",
    "                                split='train',\n",
    "                                question_tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 2\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, questions, answers = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 224, 224])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogue = torch.randint(0, 20000, (batch_size, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7951, 16511,  3728,  ..., 10789,  6294, 10876],\n",
       "        [17651,  6312,  4399,  ..., 13858,  9706,   515]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(0, 20000, (batch_size, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9371,  3759,  4601, 15279, 19101,  9200, 10932,  6262,  3960,  4517,\n",
       "        19970,  1811,  6833, 13687,  1719, 18717, 13864, 17647,  8979,  1287,\n",
       "        16146, 19115, 16185, 19267, 10832, 16590, 12013,  4944,  1766, 16188,\n",
       "        11231,  9270,  9480,  6573,  8595, 11527,  7139,  9485, 13493,  2015,\n",
       "         7621,  6743, 15780,  6575,  3489, 16592, 11258,  4916,  1901, 18272,\n",
       "         7876, 15779,  8727, 10864,  1043,  7612, 11702, 12588, 13673, 14100,\n",
       "         7308, 11839,  7253, 14456,  9238,  2126,  1893,  7938,  4282,  3568,\n",
       "        12089,  7174, 14488, 16398, 17294,  3178,  3637,  2625, 10731, 11047,\n",
       "          413,  2220, 10449, 16959,  2959,   958, 16813,  4172, 11279, 18049,\n",
       "        17363,  8292, 19531, 19374,  5192, 16038, 13807, 16454, 12272,  2722,\n",
       "         8971, 10444, 19277,  7975,  5954, 19652, 17068,  8838,  6801,  4513,\n",
       "         5479, 10516,  9131, 12774,  3071, 13605,  8305, 18306, 15422,  7926,\n",
       "        16436,  1664, 13699,  4699, 19846, 12723,  3502, 17299,  5390,  7232,\n",
       "         2292, 15253, 11351, 15416,  6769,   108, 13190, 16231,  7484, 11111,\n",
       "        15841, 14552,  5804, 12127,  2406,  4686,  6144, 14289, 12403,  1800,\n",
       "        10594, 16140, 16574, 13782,  4222, 13427,  9900,  6656,  5387, 19104,\n",
       "        14863, 11712,   763,  6148,  3815, 14583,  3626, 18717, 15272, 16867,\n",
       "        11239,  3646, 11248, 10198, 11864,   659, 15761, 17620, 19228, 10751,\n",
       "        15375, 14157,  6521,  4898,  9963,  9518, 15216,  6277,  1415,  6355,\n",
       "         1999,  8513,  2191,  1912, 17944, 11000,  3694, 19094, 15048, 19441,\n",
       "        16201,  3428,  9676,  9622,  3972,  5853,  5274, 16323, 11164,  3943,\n",
       "        15111, 11663,   290, 14162, 12187, 15260, 17629,  3858, 15015, 18876,\n",
       "        19871,  4888,  9515,  7166, 14969,  7500, 15704, 10711,  3995, 19754,\n",
       "        17563,   527, 13174,  5517, 17892, 14737,  1292,  5636, 15438, 18997,\n",
       "         6384,  1819,  5943, 14520, 16004,  9863,  5207,  6597, 14505,  5116,\n",
       "        16396, 13388,  3586, 13831,  8834,  8435, 12343, 18428,  2453, 17270,\n",
       "         5452, 18693,  5265,  6907, 13928, 16424, 15588, 12795, 14948,  3834,\n",
       "        19535,  6763, 13163,  7205,  9256, 19971,  1100, 13206,  2376, 18152,\n",
       "         7416,  8534, 12658, 12694,   364,    62, 15620,   557,  3988, 12029,\n",
       "        14004, 14983, 19695,  2966, 15087, 11185,  4880, 13130,  1619,  6302,\n",
       "         1567, 11612,  7631, 13627,  4664,  5060,   504, 19890,   835, 19094,\n",
       "        15598,  8951,  6976,  7192, 10951,   921,  6393,  7500, 11321, 16814,\n",
       "        16519, 11585, 10553, 16168, 18936, 12958,  8200,   795,  8869, 16365,\n",
       "         1823,  3308,  7300,  3336, 18888, 10024,  8983, 13792, 17993,  1448,\n",
       "         1474,  4208, 10560, 14826,   773,  3341, 15280,  5285, 16386,  6127,\n",
       "         4874,  8221,  7503, 18192, 12518,  4166, 14907, 17993, 11297,  4593,\n",
       "        15293, 16886,  7776, 12083,  4400,  6691,  8451, 12621, 10871,  1572,\n",
       "        19733,  1096,  7958,  2160, 17460, 17679, 15732, 13674,  7569, 15540,\n",
       "        19872,  5516,  2866,  4026,  6389,  4528,   726,  2154,  1376,  7263,\n",
       "         6614,    80,   157,  3423,  6439,  5607,   668, 11414,  3438, 11742,\n",
       "        16478,   339,  9175,  9026, 13528,  7261, 10569,  8957, 18353,  9398,\n",
       "         3624,  4754, 13681, 11499, 10748, 14078,  8675,  3406,  8219, 16576,\n",
       "         5746,  3678, 17418, 18934, 17111,  7085, 18803, 18156,  2700,  2991,\n",
       "        16037, 15754,  6560,  9706,  4596, 13613, 15656, 19304,  4723, 14035,\n",
       "        10420, 12203, 13619,  1499, 14351,  5934, 14361,  4624, 14797,  7665,\n",
       "         2850, 11920, 16095, 16106, 11455,  7571,  5584, 12284, 14143,  8816,\n",
       "         3853, 19464,  9920,  2155,  7103, 14144,  2749, 10743,   779, 12122,\n",
       "         2971,  5936,  7090, 18814, 14115,  3324,   964, 15768,  5634, 19220,\n",
       "         7779, 14327, 19911,  2647,  7974, 18346, 19282,   229,  2553, 15503,\n",
       "         9200,  4992, 17639,  1466, 13599,  7769,  3263, 15455, 10323,  7050,\n",
       "         9174,  4238,  1993, 17919,  6639, 12487,  1567, 13000,  5928,  8046,\n",
       "         7313,   541])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogue[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogue.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "flamingo_logits = flamingo_palm(dialogue, train_features.unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('What is the observed sign of pulmonary consolidation on the right side?',\n",
       "  'What is abnormal with the ventricles?'),\n",
       " ('blunting of the costophrenic angle, loss of the right hemidiaphragm and right heart border',\n",
       "  'Lateral and third ventricular hydrocephalus'))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions,answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512, 20000])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flamingo_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"allenai/scibert_scivocab_uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the observed sign of pulmonary consolidation on the right side?'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(list(questions), padding=True, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  102,  1792,   165,   111,  1058,   423,   131,  5186, 19074,   191,\n",
       "           111,  2083,  2480,  3912,   103],\n",
       "        [  102,  1792,   165,  4592,   190,   111, 15077, 30113,  3912,   103,\n",
       "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='allenai/scibert_scivocab_uncased', vocab_size=31090, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "892a7f8aeabe86b99d45932805d162784b758c544538f3ce4737e4a115db3cfd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch-nightly')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
