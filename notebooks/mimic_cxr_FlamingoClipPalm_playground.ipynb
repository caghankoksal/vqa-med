{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import comet_ml at the top of your file\n",
    "import comet_ml\n",
    "from pytorch_lightning.loggers import CometLogger\n",
    "import sys \n",
    "sys.path.append('..')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.datasets.mimic_cxr_dataset import MIMICCXRDataModule\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "import torchvision.transforms as T\n",
    "import torch\n",
    "# sets seeds for numpy, torch, python.random and PYTHONHASHSEED.\n",
    "seed_everything(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "augmentations = {'train':\n",
    "    T.Compose(\n",
    "    [\n",
    "        T.Resize((224, 224)),\n",
    "        T.RandomApply([T.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.1)], p=0.8),\n",
    "        T.RandomGrayscale(p=0.2),\n",
    "        T.GaussianBlur(kernel_size=9),\n",
    "        T.ToTensor(),\n",
    "    ]),\n",
    "    'val':\n",
    "    T.Compose(\n",
    "    [\n",
    "        T.Resize((224, 224)),\n",
    "        T.RandomApply([T.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.1)], p=0.8),\n",
    "        T.RandomGrayscale(p=0.2),\n",
    "        T.GaussianBlur(kernel_size=9),\n",
    "        T.ToTensor(),\n",
    "    ])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 200\n",
    "LIMIT_NUM_SAMPLES = 64\n",
    "NUM_DATA_WORKERS  = 0\n",
    "ONLY_IMAGES = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/caghankoksal/Desktop/development/Flamingo-playground/physionet.org/files/mimic-cxr/2.0.0/files/'\n",
    "mimic_datamodule = MIMICCXRDataModule(data_path, transforms=augmentations, only_images=False, batch_size=BATCH_SIZE,\n",
    "                                limit_num_samples=LIMIT_NUM_SAMPLES, num_data_workers=NUM_DATA_WORKERS, tokenizer=\"gpt2\")\n",
    "train_loader = mimic_datamodule.train_dataloader()\n",
    "val_loader = mimic_datamodule.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mimic_datamodule.train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    print(\"Image shape : \",batch[\"image\"].shape)\n",
    "    print(batch[\"text\"][0]) # First sample in the batch\n",
    "    print(\"Input Ids shape : \",batch[\"input_ids\"].shape)\n",
    "    print(\"Targets shape : \",batch[\"targets\"].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.multimodal.flamingo_module import FlamingoModule\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE_OF_TOKENIZER = mimic_datamodule.train_dataset.tokenizer.vocab_size\n",
    "VOCAB_SIZE_OF_TOKENIZER\n",
    "LANGUAGE_MODEL = 'gpt2'\n",
    "NUM_TOKENS = VOCAB_SIZE_OF_TOKENIZER+3 if LANGUAGE_MODEL==\"gpt2\" else 31092\n",
    "FLAMINGO_EMBED_DIM = 768\n",
    "DEPTH = 12\n",
    "NUM_HEADS = 8\n",
    "ATT_HEAD_DIM = 64\n",
    "CROOS_ATT_EVERY=3\n",
    "MEDIA_TOKEN_ID = mimic_datamodule.train_dataset.tokenizer.all_special_ids[mimic_datamodule.train_dataset.tokenizer.all_special_tokens.index('<image>')]\n",
    "PERCEIVER_NUM_LATENTS = 64\n",
    "PERCEIVER_DEPTH = 2\n",
    "IMAGE_ENCODER = \"clip\"\n",
    "PRETRAINED_CLIP_PATH = '/Users/caghankoksal/Desktop/development/PubMedCLIP_ViT32.pth'\n",
    "PRETRAINED_GPT2_PATH = \"/Users/caghankoksal/Desktop/development/TransformerPlay/gpt2-pytorch_model.bin\"\n",
    "\n",
    "print(\"LANGUAGE_MODEL : \",LANGUAGE_MODEL, \"\\n\"\n",
    "        \"NUM_TOKENS : \",NUM_TOKENS, \"\\n\"\n",
    "        \"FLAMINGO_EMBED_DIM : \",FLAMINGO_EMBED_DIM, \"\\n\"\n",
    "        \"DEPTH : \",DEPTH, \"\\n\"\n",
    "        \"NUM_HEADS : \",NUM_HEADS, \"\\n\"\n",
    "        \"ATT_HEAD_DIM : \",ATT_HEAD_DIM, \"\\n\"\n",
    "        \"CROOS_ATT_EVERY : \",CROOS_ATT_EVERY, \"\\n\"\n",
    "        \"MEDIA_TOKEN_ID : \",MEDIA_TOKEN_ID, \"\\n\"\n",
    "        \"PERCEIVER_NUM_LATENTS : \",PERCEIVER_NUM_LATENTS, \"\\n\"\n",
    "        \"PERCEIVER_DEPTH : \",PERCEIVER_DEPTH, \"\\n\"\n",
    "        \"IMAGE_ENCODER : \",IMAGE_ENCODER, \"\\n\"\n",
    "        \"PRETRAINED_CLIP_PATH : \",PRETRAINED_CLIP_PATH, \"\\n\"\n",
    "        \"PRETRAINED_GPT2_PATH : \",PRETRAINED_GPT2_PATH, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FlamingoModule(pretrained_clip_path = PRETRAINED_CLIP_PATH,\n",
    "                      total_steps=100, num_tokens = NUM_TOKENS,\n",
    "                      dim=FLAMINGO_EMBED_DIM, depth=DEPTH, heads=NUM_HEADS, dim_head=ATT_HEAD_DIM,\n",
    "                      media_token_id=MEDIA_TOKEN_ID, cross_attn_every=CROOS_ATT_EVERY,\n",
    "                      perceiver_num_latents = PERCEIVER_NUM_LATENTS, perceiver_depth = PERCEIVER_DEPTH,\n",
    "                      image_encoder =IMAGE_ENCODER, language_model = LANGUAGE_MODEL,\n",
    "                      pretrained_gpt2_path=PRETRAINED_GPT2_PATH\n",
    "                        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMET_API_KEY = \"F2L19mQwKXSoeF1IYEDA2AeHD\",\n",
    "PROJECT_KEY = \"flamingo-playground\",\n",
    "import os\n",
    "from pytorch_lightning.loggers import CometLogger\n",
    "\n",
    "comet_logger = CometLogger(\n",
    "    api_key= \"F2L19mQwKXSoeF1IYEDA2AeHD\",\n",
    "    project_name=\"flamingo-gpt2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import loggers as pl_loggers\n",
    "\n",
    "tb_logger = pl_loggers.TensorBoardLogger(save_dir=\"pll_logs/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(max_epochs=6,deterministic=True,\n",
    "                     accelerator=\"cpu\", devices=1,\n",
    "                     logger=[tb_logger,comet_logger],\n",
    "                     callbacks=[lr_monitor],\n",
    "                     log_every_n_steps=1,\n",
    "                     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comet_logger.experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir=pll_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torchxrayvision as xrv\n",
    "image_encoder = xrv.models.DenseNet(weights=\"densenet121-res224-mimic_nb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch-nightly')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "892a7f8aeabe86b99d45932805d162784b758c544538f3ce4737e4a115db3cfd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
