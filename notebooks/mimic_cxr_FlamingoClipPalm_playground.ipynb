{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('..')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from src.datasets.mimic_cxr_dataset import MIMICCXRDataModule\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "import torchvision.transforms as T\n",
    "# sets seeds for numpy, torch, python.random and PYTHONHASHSEED.\n",
    "seed_everything(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "augmentations = {'train':\n",
    "    T.Compose(\n",
    "    [\n",
    "        T.Resize((224, 224)),\n",
    "        T.RandomApply([T.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.1)], p=0.8),\n",
    "        T.RandomGrayscale(p=0.2),\n",
    "        T.GaussianBlur(kernel_size=9),\n",
    "        T.ToTensor(),\n",
    "    ]),\n",
    "    'val':\n",
    "    T.Compose(\n",
    "    [\n",
    "        T.Resize((224, 224)),\n",
    "        T.RandomApply([T.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.1)], p=0.8),\n",
    "        T.RandomGrayscale(p=0.2),\n",
    "        T.GaussianBlur(kernel_size=9),\n",
    "        T.ToTensor(),\n",
    "    ])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n"
     ]
    }
   ],
   "source": [
    "data_path = '/Users/caghankoksal/Desktop/development/Flamingo-playground/physionet.org/files/mimic-cxr/2.0.0/files/'\n",
    "mimic_datamodule = MIMICCXRDataModule(data_path, transforms=augmentations, only_images=False, batch_size=1,\n",
    "                                limit_num_samples=None, num_data_workers=0, tokenizer=\"gpt2\")\n",
    "train_loader = mimic_datamodule.train_dataloader()\n",
    "val_loader = mimic_datamodule.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4355"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mimic_datamodule.train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4355"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape :  torch.Size([1, 3, 224, 224])\n",
      "<|endoftext|> <image> Output: FINAL REPORT AP CHEST 1:28 A.M.  HISTORY:  -year-old woman with pneumonia and C. difficile infection. IMPRESSION:  AP chest compared to  through : There has been very little change in the appearance of the lungs in this patient with severe pulmonary fibrosis over the course of this hospitalization, probably a function of either concurrent pneumonia or acceleration of pulmonary fibrosis.  Small bilateral pleural effusions have appeared intermittently, greater today than yesterday, suggesting some component of cardiac decompensation.  ET tube is in standard placement.  PIC line ends in the region of the superior cavoatrial junction alongside a right internal jugular line.  Nasogastric tube passes below the diaphragm and out of view.  No pneumothorax. <EOC>\n",
      "Input Ids shape :  torch.Size([1, 1, 256])\n",
      "Targets shape :  torch.Size([1, 1, 256])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    print(\"Image shape : \",batch[\"image\"].shape)\n",
    "    print(batch[\"text\"][0])# First sample in the batch\n",
    "    print(\"Input Ids shape : \",batch[\"input_ids\"].shape)\n",
    "    print(\"Targets shape : \",batch[\"targets\"].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27200"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 200\n",
    "len(mimic_datamodule.train_dataset)//BATCH_SIZE*NUM_EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50258"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mimic_datamodule.train_dataset.tokenizer.all_special_ids[mimic_datamodule.train_dataset.tokenizer.all_special_tokens.index('<image>')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50256, 50257, 50258, 50259]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mimic_datamodule.train_dataset.tokenizer.all_special_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.multimodal.flamingo_module import FlamingoModule\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE_OF_TOKENIZER = mimic_datamodule.train_dataset.tokenizer.vocab_size\n",
    "VOCAB_SIZE_OF_TOKENIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGUAGE_MODEL = 'gpt2'\n",
    "NUM_TOKENS = VOCAB_SIZE_OF_TOKENIZER+3 if LANGUAGE_MODEL==\"gpt2\" else 31092\n",
    "FLAMINGO_EMBED_DIM = 768\n",
    "DEPTH = 12\n",
    "NUM_HEADS = 8\n",
    "ATT_HEAD_DIM = 64\n",
    "CROOS_ATT_EVERY=3\n",
    "MEDIA_TOKEN_ID = mimic_datamodule.train_dataset.tokenizer.all_special_ids[mimic_datamodule.train_dataset.tokenizer.all_special_tokens.index('<image>')]\n",
    "PERCEIVER_NUM_LATENTS = 64\n",
    "PERCEIVER_DEPTH = 2\n",
    "IMAGE_ENCODER = \"clip\"\n",
    "LANGUAGE_MODEL = \"gpt2\"\n",
    "PRETRAINED_CLIP_PATH = '/Users/caghankoksal/Desktop/development/PubMedCLIP_ViT32.pth'\n",
    "PRETRAINED_GPT2_PATH = \"/Users/caghankoksal/Desktop/development/TransformerPlay/gpt2-pytorch_model.bin\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vit is started from scratch\n",
      "Vit is initialized\n",
      "Flamingo is being initialized with  gpt2  as language model\n",
      "GPT 2 Weights are loading...\n",
      "Loaded GPT2 weights num_weights loaed :  156\n"
     ]
    }
   ],
   "source": [
    "model = FlamingoModule(pretrained_clip_path = None,\n",
    "                        total_steps=100, num_tokens = NUM_TOKENS,\n",
    "                        dim=FLAMINGO_EMBED_DIM, depth=DEPTH, heads=NUM_HEADS, dim_head=ATT_HEAD_DIM,\n",
    "                        media_token_id=MEDIA_TOKEN_ID, cross_attn_every=CROOS_ATT_EVERY,\n",
    "                        perceiver_num_latents = PERCEIVER_NUM_LATENTS, perceiver_depth = PERCEIVER_DEPTH,\n",
    "                        image_encoder =IMAGE_ENCODER, language_model = LANGUAGE_MODEL,\n",
    "                        pretrained_gpt2_path=PRETRAINED_GPT2_PATH\n",
    "                        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | flamingo_palm | FlamingoModel | 202 M \n",
      "------------------------------------------------\n",
      "161 M     Trainable params\n",
      "41.0 M    Non-trainable params\n",
      "202 M     Total params\n",
      "809.749   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a713d49937b54aa3bb12e7f5e8e953e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=200,deterministic=True,\n",
    "                     accelerator=\"cpu\", devices=1)\n",
    "trainer.fit(model, train_dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch-nightly')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "892a7f8aeabe86b99d45932805d162784b758c544538f3ce4737e4a115db3cfd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
